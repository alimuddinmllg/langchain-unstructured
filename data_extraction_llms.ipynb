{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet pypdf pandas streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import  Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import  BaseModel, Field\n",
    "\n",
    "# Other modules and packages\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(OPENAI_API_KEY)  # Should not be None or empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-c138a6be-224f-43ad-8ad0-5d304407cea5-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', api_key=OPENAI_API_KEY)\n",
    "llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 0}, page_content='Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\\nVarna, Bulgaria, Sep 2–4, 2019.\\nhttps://doi.org/10.26615/978-954-452-056-4_087\\n750\\nSentiment and Emotion Based Text\\nRepresentation for Fake Reviews Detection\\nAlimuddin Melleng\\nQueen’s University Belfast\\namelleng01@qub.ac.uk\\nAnna-Jurek Loughrey\\nQueen’s University Belfast\\na.jurek@qub.ac.uk\\nDeepak P\\nQueen’s University Belfast\\ndeepaksp@acm.org\\nAbstract\\nFake reviews are increasingly prevalent\\nacross the Internet. They can be uneth-\\nical and harmful. They can affect busi-\\nnesses and mislead customers. As opin-\\nions on the Web are increasingly relied on,\\nthe detection of fake reviews has become\\nmore critical. In this study we explore\\nthe effectiveness of sentiment and emo-\\ntions based representations for the task\\nof building machine learning models for\\nfake reviews detection. The experiment\\nperformed with three real-world datasets\\ndemonstrate that improved data represen-\\ntation can be achieved by combining sen-\\ntiment and emotion extraction methods, as\\nwell as by performing sentiment and emo-\\ntion analysis on a part-by-part basis by\\nsegmenting the reviews.\\n1 Introduction\\nThe Internet has evolved into a content creation\\nplatform where people express their opinions and\\nexperiences. Online reviews written by users have\\nsigniﬁcant impact on customers and companies.\\nPotential customers often consult reviews before\\nmaking a purchase. Reviews help potential cus-\\ntomers to gain insights from other people’s ex-\\nperiences, particularly in making choices on pur-\\nchasing products or services. At the same time,\\ncompanies need reviews on their products or ser-\\nvices in order to get feedback and maintain good\\nreputation. However, not all reviews available in\\nthe Internet are genuine. Profusion of reviews\\nof questionable quality increase concerns about\\ntheir trustworthiness. Moreover, users with mal-\\nintent often post fake reviews (FR) to mislead cus-\\ntomers by promoting or demoting products or tar-\\nget stores. Authors of FR can sway customer\\nchoices towards companies with which they are\\nassociated, or against competitors making fake re-\\nviews a lucrative business. There has been an in-\\ncrease in FR profusion lately. According to the\\nreport of the Harvard Business School (Luca and\\nZervas, 2016) the percentage of fake reviews on\\nYELP1 increased from 5 % in 2006 to 20% in\\n2013. This makes FR detection an important chal-\\nlenge to be addressed.\\nFR were ﬁrstly categorized by Jindal et al.\\n(2008) into three groups: (1) Untruthful opin-\\nions: mislead readers by giving positive reviews\\nto promote or demote target object, (2) Reviews\\non brands only: the reviewer focus on the brands,\\nproducers or sellers of a product or service without\\ncommenting on the product or service, (3) Non-\\nreviews: the reviews are irrelevant to the product\\nand do not contain opinions but advertisements or\\nquestions. The ﬁrst category is the most challeng-\\ning type to detect, and that is the focus of our pa-\\nper. Given the large numbers of reviews posted\\ndaily, automatic methods would be preferred over\\nmanual ones as illustrated in (Ott et al., 2011). Re-\\ncent years have witnessed an increased impetus on\\nmachine learning methods for data-driven FR de-\\ntection (Mukherjee et al., 2013; Ott et al., 2011;\\nRout et al., 2017)\\nThe performance of machine learning mod-\\nels for detecting FR is heavily inﬂuenced by the\\ndata representation (or features) in their applica-\\ntion (Bengio et al., 2013). Text analytics has\\nconventionally focused on domains such as la-\\nbelling news stories or grouping disease reports\\nbased on severity where the human authors of\\ntext documents are largely passive to the usage\\nof downstream analytics. FR mitigation meth-\\nods, on the other hand, are in direct conﬂict with\\nthe intents of FR peddlers, generating interest-\\n1https://www.yelp.co.uk/'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 1}, page_content='751\\ning gamiﬁcation dynamics. This makes it impor-\\ntant for data-driven FR solutions to rely on more\\ngeneric or higher-level data representations rather\\nthan simple lexical ones based on words, phrases\\nand sentences. This is because FR ﬁlters using\\nhigher-level generic features may naturally be ex-\\npected to be more robust and resistant to sim-\\nple workarounds by FR authors such as word and\\nphrase replacements. Further, higher-level fea-\\ntures may have limited volatility across domains;\\nthus, FR detection methods based on them may be\\nmore transferable across domains.\\nIn this paper, we evaluate the effectiveness of\\nemotion and sentiment based representations for\\nthe task of building machine learning models for\\nFR detection. In particular, we illustrate that im-\\nproved data representations can be achieved by\\nleveraging a plurality of emotion and sentiment\\nextraction methods, as well as by estimating emo-\\ntions and sentiments on a part-by-part basis by\\nsegmenting the reviews. We illustrate the im-\\nproved effectiveness of multiple emotion and sen-\\ntiment features as well as review-segmented fea-\\ntures by evaluating over real-world datasets.\\n2 Related Work\\nRepresentation learning focuses on developing a\\nmore instructive feature set for training a classi-\\nﬁcation model that helps to boost the FR detec-\\ntion process (Li et al., 2017; Yilmaz and Durahim,\\n2018). Within past research, diverse features se-\\nlection methods have been employed to detect FR.\\nThese may be divided into two classes: review-\\ncentric and reviewer-centric features. Reviewer-\\ncentric features are related to the reviewer’s be-\\nhaviour (Fontanarava et al., 2017) rather than\\nthe review itself. Those features include tex-\\ntual features, rating features, and temporal fea-\\ntures. Review-centric features are derived from\\nthe content of a review. Commonly used review-\\ncentric features include Bag-of-words, TF-IDF\\n(Term-frequency inverse-document- frequency),\\nPOS (part of speech) tags, word n-grams (Ahmed\\net al., 2018), and word embedding vectors (e.g.\\nWord2vec, Doc2vec) (Krishnamurthy et al., 2018;\\nYilmaz and Durahim, 2018). A recent study by Jia\\net al. (2018) explored the application of linguis-\\ntic features to distinguish between fake and non-\\nfake reviews. They used Yelp ﬁlter dataset in their\\nstudy and applied Term Frequency, Word2vec, and\\nLatent Topic Distribution for data representation.\\nThey trained three machine learning models i.e.\\nSVM, Logistic Regression, and Multi-layer Per-\\nceptron and found that LDA+Logistic Regression\\nand LDA+Multi-layer Perceptron performed bet-\\nter with 81.3% of accuracy.\\nWith representations being only a means to en-\\nable better FR identiﬁcation, it is useful to brieﬂy\\noutline the classiﬁcation techniques that have been\\nemployed for FR detection. Ott et al., (2011) used\\nword n-gram features in combination with a SVM\\nclassiﬁer. Banerjee and Chua (2014) employed a\\nLogistic Regression classiﬁer over POS tags and\\nwriting style features (e.g., tense of words) for\\nFR detection. Algur et al., (2010) explored a\\nsimilarity-oriented method for FR detection over\\ndomain-speciﬁc product features.\\nAs mentioned earlier, our representations are\\ncentred on emotion and sentiment based features.\\nThere has been very little prior work on using such\\nfeatures for FR detection. An early work in senti-\\nment analysis for FR detection was conducted by\\nPeng and Zhong (2014), whereas (K et al., 2019)\\nexplore utility of emotions in health fake news de-\\ntection. Peng and Zhong (2014) chose SentiWord-\\nNet and MPQA lexicons and analysed sentiment\\non review and product features. In our experiment,\\nwe used IBM, Aﬁnn, SenticNet, and Biu Liu lexi-\\ncons. To our knowledge, this is the ﬁrst study de-\\ntecting FR by means of combination emotion and\\nsentiment analysis. Taking cue from the previous\\nwork of FR detection, we use Random Forest clas-\\nsiﬁer, in our experiments.\\n3 Methodology\\nIn this section we describe our proposed approach\\nto online FR detection using emotion and senti-\\nment based text representation.\\n3.1 Emotion and Sentiment Analysis\\nFor the purpose of sentiment and emotion anal-\\nysis, we apply three different sentiment lexicons\\nand one emotion analysis API.\\n•IBM Watson Natural Language Understand-\\ning. Natural Language Understanding (NLU) 2\\nis a collection of APIs that offer text analy-\\nsis through natural language processing. One\\nof the feature of IBM Watson NLU is emo-\\ntion analysis. The API takes a text as\\nan input and returns the category which the\\n2https://www.ibm.com/services/natural-language-\\nunderstanding/'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 2}, page_content='752\\ntext belongs to, stored in a list variable: <\\nKeyV aluePair < String, Double >>e.g.\\n”emotion” : {”sadness”:0.336228}. Each item\\nin the list contains the category (emotion) name\\nand the categorization score. IBM Watson NLU\\ncan detect ﬁve emotions: anger, disgust, fear,\\njoy, and sadness. For example, for an an input ’I\\nlove apples! I don’t like oranges’, the NLU API\\nreturns (sadness: 0.32665, joy: 0.563273, fear:\\n0.033387, disgust: 0.022637, anger: 0.041796).\\n•SenticNet lexicon. SenticNet3 performs tasks\\nsuch as polarity detection and emotion recog-\\nnition. Instead of merely relying on word co-\\noccurrence frequencies, it leverages semantics\\nand linguistics. This lexicon contains a list of\\nwords with their polarity and intensity values.\\nThe intensity is a ﬂoat number between -1 and\\n+1. For example, according to the SenticNet\\nlexicon ’abandoned’ is a negative word with in-\\ntensity of -0.85. Each word in the lexicon is\\nassigned with only one polarity and intensity\\nvalue.\\n•AFINN lexicon. AFINN4 lexicon is a list of\\nEnglish terms rated with valence on a scale -5\\n(negative) and +5 (positive). This lexicon has\\nbeen manually labelled by Finn ˚Arup Nielsen\\n(2011). AFINN provides two versions of lexi-\\ncon: the newest version AFINN-111 with 2477\\nwords and phrases and AFINN-96 with 1468\\nunique words and phrases on 1480 lines. Our\\nexperiment use AFINN-111 as it is the most up-\\nto-date version.\\n•Biu Liu lexicon. Biu Liu5 lexicon consists of\\n6789 words including 2006 positive and 4783\\nnegative words (Hu and Liu, 2004). This lexi-\\ncon does not provide any sentiment scores and\\nonly provides positive/negative labels.\\n3.2 Representation Learning\\nIn this work we explore whether sentiment and\\nemotions extracted from a review can be used to\\ntrain machine learning models for distinguishing\\nbetween fake and non-fake reviews. We perform\\nthe sentiment/emotion analysis with different lev-\\nels of granularity on a part-by-part basis by seg-\\nmenting the reviews.\\n3https://sentic.net/\\n4https://pypi.org/project/aﬁnn/\\n5http://www.cs.uic.edu/˜liub/FBS/opinion-lexicon-\\nEnglish.rar\\n3.2.1 Sentiment Based Representation\\nThe process of constructing sentiment based rep-\\nresentation of a review is presented in Algorithm\\n1. We ﬁrst split a review into P segments,\\neach one containing the same number of sen-\\ntences. For example, if P=4, then we split a\\nreview into 4 segments. For each segment we\\nidentify all positive and all negative words us-\\ning the lexicons. In the next step, all positive\\nsentiment values and all negative sentiment val-\\nues within the segment are accumulated together.\\nIn the case of AFINN and SenticNet, all posi-\\ntive and negative values are summed in each seg-\\nment. For Biu Liu lexicon, all positive and all\\nnegative words are counted. Following this, the\\nsegment is represented by a two dimensional vec-\\ntor [pos(si), neg(si)], where pos(si) and neg(si)\\nrepresent the accumulated/counted positive and\\nnegative sentiment values. Finally, all P vec-\\ntors (one generated for each segment) are concate-\\nnated. The concatenated vector is returned as the\\nsentiment representation of the entire review. The\\nprocess looks the same for all sentiment lexicons.\\nAlgorithm 1Sentiment Based Representation\\nInput: Review R, number of segments P, senti-\\nment lexicon L\\nOutput: Sentiment representation of R\\n1: Split R into P equal segments s1, . . . , sP\\n2: for alls1, . . . , sP do\\n3: Tokenise si into set of words W\\n4: Retrieve sentiment values for all words in\\nW using L\\n5: Accumulate all positive sentiment values in\\nW as pos(si)\\n6: Accumulate all negative sentiment values in\\nW as neg(si)\\n7: vi = [pos(si), neg(si)]\\n8: end for\\n9: v(R) := [v1, . . . , vP ]\\n10: return v(R)\\n3.2.2 Emotion Based Representation\\nThe process of generating emotion based repre-\\nsentation is presented in Algorithm 2. As in the\\ncase of the sentiment based representation, a re-\\nview is ﬁrst divided in P segments. All sentences\\nin each segment is then passed to the IBM Watson\\nAPI. As the output we obtain vector with the ﬁve\\nemotions’ scores. Finally, the emotion vectors ob-\\ntained for all the segments are concatenated. The'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 3}, page_content='753\\noutput vector is returned as the emotion represen-\\ntation of the entire review.\\nAlgorithm 2Emotion based Representation\\nInput: Review R, number of segments P, emo-\\ntion lexicon L\\nOutput: Emotion representation of R\\n1: Split R into P equal segments s1, . . . , sP\\n2: for alls1, . . . , sP do\\n3: Get vector vi with emotions scores from L\\n4: end for\\n5: v(R) := [v1, . . . , vP ]\\n6: return v(R)\\n3.2.3 Multi-Segment Based Representation\\nThe process of multi-segment representation\\nlearning is presented in Algorithm 3. With this\\ntechnique, the sentiment/emotion based represen-\\ntation is ﬁrst generated for different numbers of\\nsegments 1 . . . P. Following this, all vectors ob-\\ntained for p = 1. . . Pare concatenated to form the\\nﬁnal representation. In this way, the output vector\\ncontains more granular information on the distri-\\nbution of sentiment or emotions within a review.\\nAlgorithm 3Multi-Segment Representation\\nInput: Review R, maximum number of segments\\nP, lexicon L\\nOutput: Vector representation of R\\n1: for allp ∈1 . . . Pdo\\n2: Obtain vp(R) calling Algorithm 1 or 2 and\\npassing R, p and L as parameters\\n3: end for\\n4: v(R) := [v1(R), . . . , vP (R)]\\n5: return v(R)\\n3.2.4 Combined Sentiment and Emotion\\nBased Representation\\nThe last representation type that we explore is the\\ncombined sentiment and emotion based represen-\\ntation. The process is presented in Algorithm 4.\\nFirst, a review is divided into P segments. The\\nrepresentation of each segment is generated by\\nconcatenation of sentiment and emotion represen-\\ntations obtained with Algorithms 1 and 2 respec-\\ntively. Finally, representations of all segments are\\nmerged together.\\nAlgorithm 4 Combined sentiment and Emotion\\nBased Representation\\nInput: Review R, number of segments P, senti-\\nment lexicon Ls, emotion lexicon Le\\nOutput: Vector representation of R\\n1: Split R into P equal segments s1, . . . , sP\\n2: for alls1, . . . , sP do\\n3: Get sentiment representation Vs(R) apply-\\ning Algorithm 1 with R, P and Ls\\n4: Get emotion representation Ve(R) applying\\nAlgorithm 2 with R, P and Le\\n5: vi = [Vs(R), Ve(R)]\\n6: end for\\n7: v(R) := [v1, . . . , vP ]\\n8: return v(R)\\n4 Experimental Results and Discussion\\nIn this section we present the experimental\\nevaluation of the proposed four different senti-\\nment/emotion based representations. Each of the\\nrepresentations are separetely used to build a ma-\\nchine learning model for FR detection. We con-\\nducted an extensive set of experiments in order to\\nanswer the following key questions:\\n•Do sentiment/emotion based representations\\nhelp in FR detection?\\n•Which of the proposed representations is the\\nmost effective for FR detection?\\n•Can higher sentiment/emotion granularity level\\nimprove the data representation?\\n4.1 Experimental Setup\\nDatasets. We collected our datasets from two\\ndifferent sources. We used gold standard spam\\nreview dataset from Ott et al., (2011), and Yelp\\ndataset from Rayana and Akoglu (2015). The Ott\\ndataset contains reviews about hotels. Yelp Zip\\nand Yelp NYC are extracted from Yelp ﬁltered\\ndataset. Yelp NYC is a collection of reviews from\\nrestaurants located in New York City (NYC) while\\nYelp Zip is a collection of restaurant’s reviews in\\nzip code area in NY State. Each of the datasets\\ncontains true labels of the reviews, i.e. fake or\\nnon-fake label assigned to each review. Table 1\\nshows the size and class distribution for each of\\nthe datasets. In our experiment, we only con-\\nsider reviews that contain more than 10 sentences.\\nWe presume that proposed representation learning\\ntechniques would not be effective for short reviews'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 4}, page_content='754\\nsince sparse text does not allow to identify emo-\\ntions and sentiments well. Table 2 demonstrates\\nthe statistics of the datasets after ﬁltering.\\nDataset Non-fake Fake\\nYELP ZIP 528019 80439\\nYELP NYC 322097 36860\\nOtt 800 800\\nTable 1: Statistics of the datasets\\nDataset Non-fake Fake\\nYELP ZIP 170261 15108\\nYELP NYC 105080 6185\\nOtt 340 270\\nTable 2: Statistics of the datasets after ﬁltering\\nLearning. As the machine learning algorithm we\\nused Random Forest (RF) given that it was re-\\nported as one of the most effective in FR detection\\n(Chowdhary and Pandit, 2018; Saumya and Singh,\\n2018; Viviani and Pasi, 2017). However, any other\\nlearning algorithm can be applied instead. We set\\nn estimator=100 and random state=42 for the RF\\nparameter. All the experiments are performed with\\n5-fold cross-validation and the prediction perfor-\\nmance is evaluated with application of F-measure.\\nGiven the very high class imbalance in the Yelp\\nNYC and Yelp Zip, we randomly select number\\nof non-fake reviews equal to the number of FR in\\norder to balance the training data.\\n4.2 Sentiment and Emotion Granularity\\nIn this section we investigate what level of gran-\\nularity in terms of sentiment and emotion is the\\nmost representative for FR detection. Tables 3-5\\ndemonstrate the F-measure obtained by RF with\\neach of the datasets and sentiment and emotion\\nbased representations for reviews. For the param-\\neter P we used values from 1 to 4. For each ta-\\nble, the ﬁrst row represents results obtained by RF\\napplied with the emotion based representation ob-\\ntained with the IBM Watson API. The three bot-\\ntom columns contain results obtained for the sen-\\ntiment based representation generated with each of\\nthe three sentiment lexicons. Each column refers\\nto a different value of parameter P = 1×4. The\\nlast column presents results obtained for multi-\\nsegment based representation.\\nWe can observe from the tables that in the ma-\\njority of cases, the higher the granularity ( P) the\\nbetter the prediction performance. It can also be\\nnoted that the multi-segment based representation\\ntends to perform better than when a single segmen-\\ntation is applied. The only exception is the Biu Liu\\nlexicon, which for Yelp, Zip, and Ott obtained the\\nbest results for P = 1.\\nLexicon P=1 P=2 P=3 P=4 P1-4\\nIBM 0.570 0.584 0.589 0.584 0.597\\nSenticNet 0.506 0.510 0.522 0.523 0.524\\nBiu Liu 0.574 0.540 0.547 0.558 0.557\\nAFINN 0.550 0.542 0.549 0.555 0.563\\nTable 3: RF’s F-measure over Yelp ZIP dataset.\\nLexicon P=1 P=2 P=3 P=4 P1-4\\nIBM 0.554 0.569 0.578 0.569 0.584\\nSenticNet 0.511 0.520 0.523 0.525 0.526\\nBiu Liu 0.546 0.523 0.543 0.543 0.555\\nAFINN 0.524 0.529 0.541 0.544 0.557\\nTable 4: RF’s F-measure over Yelp NYC dataset.\\nLexicon P=1 P=2 P=3 P=4 P1-4\\nIBM 0.620 0.605 0.543 0.533 0.590\\nSenticNet 0.533 0.529 0.483 0.525 0.570\\nBiu Liu 0.618 0.561 0.592 0.576 0.600\\nAFINN 0.523 0.560 0.580 0.545 0.600\\nTable 5: RF’s F-measure over Ott dataset.\\n4.3 Sentiment vs. Emotion\\nIn this section we compare the results obtained by\\nRF applied with the sentiment and the emotion\\nbased representations of data. We can see from\\nTables 3-5 that IBM emotion lexicon obtained the\\nbest performance in comparison to the three senti-\\nment lexicons in the Yelp Zip and NYC datasets.\\nThis may be considered unsurprising since emo-\\ntions provide more ﬁne grained information for the\\nclassiﬁers to work with. For the Ott dataset, Biu\\nLiu and AFINN lexicon obtained better results for\\nsome of the greater values of P.\\nIn order to perform better comparison be-\\ntween the sentiment and emotion based rep-\\nresentations we calculated average of the re-\\nsults obtained for each of the granularity levels:\\nP1, P2, P3, P4, P1 −4. The results are demon-\\nstrated in Figure 1. We can observe from the\\ngraphs that the IBM emotion lexicon performs sig-\\nniﬁcantly better than any of the other sentiment\\nlexicons apart from the Ott dataset where it is out-\\nperformed by the Biu Liu lexicon.'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 5}, page_content='755\\nFigure 1: Average F-measure obtained for all val-\\nues of P\\n4.4 Combined Sentiment and Emotion Based\\nRepresentation\\nTable 6 demonstrates results obtained for the com-\\nbined sentiment and emotion based representation\\ngenerated according to the Algorithm 4. We can\\nobserve that for Zip and NYC datasets the best\\nresults were obtained when multi-segment based\\nrepresentation was applied. With Ott the best per-\\nformance was obtained for P1.\\nDataset P1 P2 P3 P4 P1-4\\nZIP 0.589 0.596 0.599 0.599 0.602\\nNYC 0.580 0.580 0.589 0.584 0.588\\nOtt 0.653 0.624 0.606 0.604 0.640\\nTable 6: F-measure obtained with combined sen-\\ntiment and emotion representation learning.\\nIn Figures 2-4 we compare the performance of\\nthe combined sentiment and emotion based repre-\\nsentation with the emotion based representation,\\nwhich so far obtained the most promising results.\\nWe can observe that the combined approach ob-\\ntained better results in each case, with the dif-\\nference in F-measure being quite signiﬁcant for\\nZip and NYC datasets. This demonstrate that im-\\nproved data representation can be achieved by ap-\\nplying combination of different emotion and sen-\\ntiment extraction methods.\\n5 Conclusions and Future Work\\nIn this paper, we analyzed the effectiveness of\\nemotion and sentiment based representations esti-\\nmated over varying text grabularities, for the task\\nof fake review classiﬁcation. Through an em-\\npirical study across three real-world datasets, we\\nﬁnd consistent evidence that combinations of emo-\\ntions and sentiments work better than either of\\nFigure 2: Combined sentiment-emotion vs. emo-\\ntion representation learning for Zip\\nFigure 3: Combined sentiment-emotion vs. emo-\\ntion representation learning for NYC\\nFigure 4: Combined sentiment-emotion vs. emo-\\ntion representation learning for Ott\\nthem separately. Further, we observe that com-\\nbining emotion and sentiment representations ob-\\ntained across different text granularities yields bet-\\nter accuracies over the restaurant review datasets.\\nAs future work, we plan to carry on research\\non cross domain between different datasets. We\\nalso want to observe how sentiment and emotion\\nwork on neural network model such as CNN and\\nLSTM using generic as well as custom-built lexi-\\ncons (Bandhakavi et al., 2017).'),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 6}, page_content='756\\n   \\nAcknowledgments \\nThe authors thank LPDP (Indonesia Endowment \\nFund for Education) for funding this research.  \\n \\nReferences  \\nAhmed, Hadeer, et al. “Detecting Opinion Spams and \\nFake News Using Text Classification.” Security \\nand Privacy , vol. 1, no. 1, 2017, p. e9, \\ndoi:10.1002/spy2.9. \\nAlgur, Siddu P., et al. “Conceptual Level Similarity \\nMeasure Based Review Spam Detection.” \\nProceedings of the 2010 International \\nConference on Signal and Image Processing, \\nICSIP 2010 , IEEE, 2010, pp. 416 –23, \\ndoi:10.1109/ICSIP.2010.5697509. \\nAnoop, K., et al. “Emotion Cognizance Improves Fake \\nNews Identification.” ArXiv Preprint \\nArXiv:1906.10365, 2019. \\nBandhakavi, Anil, et al. “Lexicon Generation for \\nEmotion Detection from Text.” IEEE Intelligent \\nSystems, vol. 32, no. 1, IEEE, 2017, pp. 102 –08, \\ndoi:10.1109/MIS.2017.22. \\nBanerjee, Snehasish, and Alton Y. K. Chua. \\n“Applauses in Hotel Reviews: Genuine or \\nDeceptive?” Proceedings of 2014 Science and \\nInformation Conference, SAI 2014 , The Science \\nand Information (SAI) Organization, 2014, pp. \\n938–42, doi:10.1109/SAI.2014.6918299. \\nBengio, Yoshua, et al. “Representation Learning: A \\nReview and New Perspectives. ” IEEE \\nTransactions on Pattern Analysis and Machine \\nIntelligence, vol. 35, no. 8, IEEE, 2013, pp. \\n1798–828. \\nChowdhary, Neha S., and Anala A. Pandit. “Fake \\nReview Detection Using Classification.” \\nInternational Journal of Computer Applications, \\nvol. 180, no. 50, 2018, pp. 16–21. \\nFontanarava, Julien, et al. “Feature Analysis for Fake \\nReview Detection through Supervised \\nClassification.” 2017 IEEE International \\nConference on Data Science and Advanced \\nAnalytics (DSAA), IEEE, 2017, pp. 658–66. \\nHu, Minqing, and Bing Liu. “Mining and Summarizing \\nCustomer Reviews.” Proceedings of the Tenth \\nACM SIGKDD International Conference on \\nKnowledge Discovery and Data Mining, vol. 50, \\nno. 08, 2004, pp. 50 -4466-50–4466, \\ndoi:10.5860/choice.50-4466. \\nJia, Shaohua, et al. “Fake Reviews Detection Based on \\nLDA.” 2018 4th International Conference on \\nInformation Management, ICIM 2018 , IEEE, \\n2018, pp. 280 –83, \\ndoi:10.1109/INFOMAN.2018.8392850. \\nJindal, Nitin, and Bing Liu. “Opinion Spam and \\nAnalysis.” Proceedings of the 2008 International \\nConference on Web Search and Data Mining , \\nACM, 2008, pp. 219–30. \\nKrishnamurthy, Gangeshwar, et al. “A Deep Learning \\nApproach for Multimodal Deception Detection.” \\nArXiv Preprint ArXiv:1803.00344, 2018. \\nKumar, Abhinav, et al. “Spotting Opinion Spammers \\nUsing Be havioral Footprints.” Proceedings of \\nthe 19th ACM SIGKDD International \\nConference on Knowledge Discovery and Data \\nMining, ACM, 2013, \\ndoi:10.1145/2487575.2487580. \\nLi, Luyang, et al. “Document Representation and \\nFeature Combination for Deceptive Spam \\nReview Detection.” Neurocomputing, vol. 254, \\nElsevier B.V., 2017, pp. 1339 –51, \\ndoi:10.1016/j.neucom.2016.10.080. \\nLuca, Michael, and Georgios Zervas. “Fake It till You \\nMake It: Reputation.” Competition, and Yelp \\nReview Fraud., SSRN Electronic Journal, 2016. \\nNielsen, Finn Årup. “A New ANEW: Evaluation of a \\nWord List for Sentiment Analysis in \\nMicroblogs.” CEUR Workshop Proceedings , \\nvol. 718, 2011, pp. 93 –98, \\ndoi:10.1016/j.knosys.2015.06.015. \\nOtt, Myle, et al. “Finding Deceptive Opinion Spam by \\nAny Stretch of the Imagination.” Proceedings of \\nthe 49th Annual Meeting of the Association for \\nComputational Linguistics: Human Language \\nTechnologies-Volume 1 , Association for \\nComputational Linguistics, 2011, pp. 309–19. \\nPeng, Qingxi, and Ming Zhong. “Detecting Spam \\nReview through Sentiment AnalysisPeng, Q. and \\nZhong, M. (2014) ‘Detecting Spam Review \\nthrough Sentiment Analysis’, Journal of \\nSoftware. Doi: 10.4304/Jsw.9.8.2065 -2072.” \\nJournal of Software , 2014, \\ndoi:10.4304/jsw.9.8.2065-2072. \\nRayana, Shebuti. “Collective Opinion Spam  \\nDetection\\u202f: Bridging Review Networks and \\nMetadata.” Proceedings of the 21th ACM \\nSIGKDD, 2015. \\nRout, Jitendra Kumar, et al. “Deceptive Review \\nDetection Using Labeled and Unlabeled Data.” \\nMultimedia Tools and Applications , vol. 76, no. \\n3, Multimedia Tools and Applications, 2017, pp. \\n3187–211, doi:10.1007/s11042-016-3819-y. \\n  '),\n",
       " Document(metadata={'source': '../RAG-PDF/content/emotion.pdf', 'page': 7}, page_content='757\\n   \\nSaumya, Sunil, and Jyoti Prakash Singh. “Detection of \\nSpam Reviews: A Sentiment Analysis \\nApproach.” CSI Transactions on ICT, vol. 6, no. \\n2, Springer, 2018, pp. 137–48. \\nViviani, Marco, and Gabriella Pasi. “Quantifier Guided \\nAggregation for the Veracity Assessment of \\nOnline Reviews.” International Journal of \\nIntelligent Systems, vol. 32, no. 5, Wiley Online \\nLibrary, 2017, pp. 481–501. \\nYilmaz, Cennet Merve, and Ahmet Onur Durahim. \\n“SPR2EP: A S emi-Supervised Spam Review \\nDetection Framework.” Proceedings of the 2018 \\nIEEE/ACM International Conference on \\nAdvances in Social Networks Analysis and \\nMining, ASONAM 2018 , 2018, pp. 306 –13, \\ndoi:10.1109/ASONAM.2018.8508314. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader('../RAG-PDF/content/emotion.pdf')\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200,length_function=len,separators=[\"\\n\\n\",\"\\n\", \" \"])\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_function():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\", openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding_function = get_embedding_function()\n",
    "test_vector = embedding_function.embed_query(\"cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2207434692141369}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import  load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(evaluator=\"embedding_distance\", embeddings = embedding_function)\n",
    "\n",
    "evaluator.evaluate_strings(prediction=\"Amsterdam\", reference=\"pizza\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "    \n",
    "    # Create a list of unique ids for each document based on the content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = []\n",
    "    for chunk, id in zip(chunks, ids):\n",
    "        if id not in unique_ids:\n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk)\n",
    "    \n",
    "    # Create a new Chroma databae from the documents        \n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function,\n",
    "                                        persist_directory= vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/59chk2cj6wn3knsk_207kwfm0000gp/T/ipykernel_96166/1639781205.py:24: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = create_vectorstore(chunks=chunks,\n",
    "                                 embedding_function=embedding_function,\n",
    "                                 vectorstore_path=\"vectorstore_chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Query for relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/59chk2cj6wn3knsk_207kwfm0000gp/T/ipykernel_96166/993109764.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"vectorstore_chroma\", embedding_function=embedding_function)\n"
     ]
    }
   ],
   "source": [
    "# Load vectorstore\n",
    "vectorstore = Chroma(persist_directory=\"vectorstore_chroma\", embedding_function=embedding_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}, page_content='Metadata.” Proceedings of the 21th ACM \\nSIGKDD, 2015. \\nRout, Jitendra Kumar, et al. “Deceptive Review \\nDetection Using Labeled and Unlabeled Data.” \\nMultimedia Tools and Applications , vol. 76, no. \\n3, Multimedia Tools and Applications, 2017, pp. \\n3187–211, doi:10.1007/s11042-016-3819-y.'),\n",
       " Document(metadata={'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}, page_content='Conference on Knowledge Discovery and Data \\nMining, ACM, 2013, \\ndoi:10.1145/2487575.2487580. \\nLi, Luyang, et al. “Document Representation and \\nFeature Combination for Deceptive Spam \\nReview Detection.” Neurocomputing, vol. 254, \\nElsevier B.V., 2017, pp. 1339 –51, \\ndoi:10.1016/j.neucom.2016.10.080. \\nLuca, Michael, and Georgios Zervas. “Fake It till You \\nMake It: Reputation.” Competition, and Yelp \\nReview Fraud., SSRN Electronic Journal, 2016. \\nNielsen, Finn Årup. “A New ANEW: Evaluation of a \\nWord List for Sentiment Analysis in \\nMicroblogs.” CEUR Workshop Proceedings , \\nvol. 718, 2011, pp. 93 –98, \\ndoi:10.1016/j.knosys.2015.06.015. \\nOtt, Myle, et al. “Finding Deceptive Opinion Spam by \\nAny Stretch of the Imagination.” Proceedings of \\nthe 49th Annual Meeting of the Association for \\nComputational Linguistics: Human Language \\nTechnologies-Volume 1 , Association for \\nComputational Linguistics, 2011, pp. 309–19. \\nPeng, Qingxi, and Ming Zhong. “Detecting Spam \\nReview through Sentiment AnalysisPeng, Q. and \\nZhong, M. (2014) ‘Detecting Spam Review \\nthrough Sentiment Analysis’, Journal of \\nSoftware. Doi: 10.4304/Jsw.9.8.2065 -2072.” \\nJournal of Software , 2014, \\ndoi:10.4304/jsw.9.8.2065-2072. \\nRayana, Shebuti. “Collective Opinion Spam  \\nDetection\\u202f: Bridging Review Networks and \\nMetadata.” Proceedings of the 21th ACM \\nSIGKDD, 2015. \\nRout, Jitendra Kumar, et al. “Deceptive Review \\nDetection Using Labeled and Unlabeled Data.” \\nMultimedia Tools and Applications , vol. 76, no.'),\n",
       " Document(metadata={'page': 7, 'source': '../RAG-PDF/content/emotion.pdf'}, page_content='757\\n   \\nSaumya, Sunil, and Jyoti Prakash Singh. “Detection of \\nSpam Reviews: A Sentiment Analysis \\nApproach.” CSI Transactions on ICT, vol. 6, no. \\n2, Springer, 2018, pp. 137–48. \\nViviani, Marco, and Gabriella Pasi. “Quantifier Guided \\nAggregation for the Veracity Assessment of \\nOnline Reviews.” International Journal of \\nIntelligent Systems, vol. 32, no. 5, Wiley Online \\nLibrary, 2017, pp. 481–501. \\nYilmaz, Cennet Merve, and Ahmet Onur Durahim. \\n“SPR2EP: A S emi-Supervised Spam Review \\nDetection Framework.” Proceedings of the 2018 \\nIEEE/ACM International Conference on \\nAdvances in Social Networks Analysis and \\nMining, ASONAM 2018 , 2018, pp. 306 –13, \\ndoi:10.1109/ASONAM.2018.8508314.'),\n",
       " Document(metadata={'page': 0, 'source': '../RAG-PDF/content/emotion.pdf'}, page_content='Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\\nVarna, Bulgaria, Sep 2–4, 2019.\\nhttps://doi.org/10.26615/978-954-452-056-4_087\\n750\\nSentiment and Emotion Based Text\\nRepresentation for Fake Reviews Detection\\nAlimuddin Melleng\\nQueen’s University Belfast\\namelleng01@qub.ac.uk\\nAnna-Jurek Loughrey\\nQueen’s University Belfast\\na.jurek@qub.ac.uk\\nDeepak P\\nQueen’s University Belfast\\ndeepaksp@acm.org\\nAbstract\\nFake reviews are increasingly prevalent\\nacross the Internet. They can be uneth-\\nical and harmful. They can affect busi-\\nnesses and mislead customers. As opin-\\nions on the Web are increasingly relied on,\\nthe detection of fake reviews has become\\nmore critical. In this study we explore\\nthe effectiveness of sentiment and emo-\\ntions based representations for the task\\nof building machine learning models for\\nfake reviews detection. The experiment\\nperformed with three real-world datasets\\ndemonstrate that improved data represen-\\ntation can be achieved by combining sen-\\ntiment and emotion extraction methods, as\\nwell as by performing sentiment and emo-\\ntion analysis on a part-by-part basis by\\nsegmenting the reviews.\\n1 Introduction\\nThe Internet has evolved into a content creation\\nplatform where people express their opinions and\\nexperiences. Online reviews written by users have\\nsigniﬁcant impact on customers and companies.\\nPotential customers often consult reviews before\\nmaking a purchase. Reviews help potential cus-\\ntomers to gain insights from other people’s ex-')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create retriever and get relevant chunks\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "relevant_chunks = retriever.invoke(\"What is the title of the paper\")\n",
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no. \n",
      "3, Multimedia Tools and Applications, 2017, pp. \n",
      "3187–211, doi:10.1007/s11042-016-3819-y.\n",
      "Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam \n",
      "Review Detection.” Neurocomputing, vol. 254, \n",
      "Elsevier B.V., 2017, pp. 1339 –51, \n",
      "doi:10.1016/j.neucom.2016.10.080. \n",
      "Luca, Michael, and Georgios Zervas. “Fake It till You \n",
      "Make It: Reputation.” Competition, and Yelp \n",
      "Review Fraud., SSRN Electronic Journal, 2016. \n",
      "Nielsen, Finn Årup. “A New ANEW: Evaluation of a \n",
      "Word List for Sentiment Analysis in \n",
      "Microblogs.” CEUR Workshop Proceedings , \n",
      "vol. 718, 2011, pp. 93 –98, \n",
      "doi:10.1016/j.knosys.2015.06.015. \n",
      "Ott, Myle, et al. “Finding Deceptive Opinion Spam by \n",
      "Any Stretch of the Imagination.” Proceedings of \n",
      "the 49th Annual Meeting of the Association for \n",
      "Computational Linguistics: Human Language \n",
      "Technologies-Volume 1 , Association for \n",
      "Computational Linguistics, 2011, pp. 309–19. \n",
      "Peng, Qingxi, and Ming Zhong. “Detecting Spam \n",
      "Review through Sentiment AnalysisPeng, Q. and \n",
      "Zhong, M. (2014) ‘Detecting Spam Review \n",
      "through Sentiment Analysis’, Journal of \n",
      "Software. Doi: 10.4304/Jsw.9.8.2065 -2072.” \n",
      "Journal of Software , 2014, \n",
      "doi:10.4304/jsw.9.8.2065-2072. \n",
      "Rayana, Shebuti. “Collective Opinion Spam  \n",
      "Detection : Bridging Review Networks and \n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no.\n",
      "757\n",
      "   \n",
      "Saumya, Sunil, and Jyoti Prakash Singh. “Detection of \n",
      "Spam Reviews: A Sentiment Analysis \n",
      "Approach.” CSI Transactions on ICT, vol. 6, no. \n",
      "2, Springer, 2018, pp. 137–48. \n",
      "Viviani, Marco, and Gabriella Pasi. “Quantifier Guided \n",
      "Aggregation for the Veracity Assessment of \n",
      "Online Reviews.” International Journal of \n",
      "Intelligent Systems, vol. 32, no. 5, Wiley Online \n",
      "Library, 2017, pp. 481–501. \n",
      "Yilmaz, Cennet Merve, and Ahmet Onur Durahim. \n",
      "“SPR2EP: A S emi-Supervised Spam Review \n",
      "Detection Framework.” Proceedings of the 2018 \n",
      "IEEE/ACM International Conference on \n",
      "Advances in Social Networks Analysis and \n",
      "Mining, ASONAM 2018 , 2018, pp. 306 –13, \n",
      "doi:10.1109/ASONAM.2018.8508314.\n",
      "Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\n",
      "Varna, Bulgaria, Sep 2–4, 2019.\n",
      "https://doi.org/10.26615/978-954-452-056-4_087\n",
      "750\n",
      "Sentiment and Emotion Based Text\n",
      "Representation for Fake Reviews Detection\n",
      "Alimuddin Melleng\n",
      "Queen’s University Belfast\n",
      "amelleng01@qub.ac.uk\n",
      "Anna-Jurek Loughrey\n",
      "Queen’s University Belfast\n",
      "a.jurek@qub.ac.uk\n",
      "Deepak P\n",
      "Queen’s University Belfast\n",
      "deepaksp@acm.org\n",
      "Abstract\n",
      "Fake reviews are increasingly prevalent\n",
      "across the Internet. They can be uneth-\n",
      "ical and harmful. They can affect busi-\n",
      "nesses and mislead customers. As opin-\n",
      "ions on the Web are increasingly relied on,\n",
      "the detection of fake reviews has become\n",
      "more critical. In this study we explore\n",
      "the effectiveness of sentiment and emo-\n",
      "tions based representations for the task\n",
      "of building machine learning models for\n",
      "fake reviews detection. The experiment\n",
      "performed with three real-world datasets\n",
      "demonstrate that improved data represen-\n",
      "tation can be achieved by combining sen-\n",
      "timent and emotion extraction methods, as\n",
      "well as by performing sentiment and emo-\n",
      "tion analysis on a part-by-part basis by\n",
      "segmenting the reviews.\n",
      "1 Introduction\n",
      "The Internet has evolved into a content creation\n",
      "platform where people express their opinions and\n",
      "experiences. Online reviews written by users have\n",
      "signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the title of the paper?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\n",
      "Varna, Bulgaria, Sep 2–4, 2019.\n",
      "https://doi.org/10.26615/978-954-452-056-4_087\n",
      "750\n",
      "Sentiment and Emotion Based Text\n",
      "Representation for Fake Reviews Detection\n",
      "Alimuddin Melleng\n",
      "Queen’s University Belfast\n",
      "amelleng01@qub.ac.uk\n",
      "Anna-Jurek Loughrey\n",
      "Queen’s University Belfast\n",
      "a.jurek@qub.ac.uk\n",
      "Deepak P\n",
      "Queen’s University Belfast\n",
      "deepaksp@acm.org\n",
      "Abstract\n",
      "Fake reviews are increasingly prevalent\n",
      "across the Internet. They can be uneth-\n",
      "ical and harmful. They can affect busi-\n",
      "nesses and mislead customers. As opin-\n",
      "ions on the Web are increasingly relied on,\n",
      "the detection of fake reviews has become\n",
      "more critical. In this study we explore\n",
      "the effectiveness of sentiment and emo-\n",
      "tions based representations for the task\n",
      "of building machine learning models for\n",
      "fake reviews detection. The experiment\n",
      "performed with three real-world datasets\n",
      "demonstrate that improved data represen-\n",
      "tation can be achieved by combining sen-\n",
      "timent and emotion extraction methods, as\n",
      "well as by performing sentiment and emo-\n",
      "tion analysis on a part-by-part basis by\n",
      "segmenting the reviews.\n",
      "1 Introduction\n",
      "The Internet has evolved into a content creation\n",
      "platform where people express their opinions and\n",
      "experiences. Online reviews written by users have\n",
      "signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n",
      "signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n",
      "periences, particularly in making choices on pur-\n",
      "chasing products or services. At the same time,\n",
      "companies need reviews on their products or ser-\n",
      "vices in order to get feedback and maintain good\n",
      "reputation. However, not all reviews available in\n",
      "the Internet are genuine. Profusion of reviews\n",
      "of questionable quality increase concerns about\n",
      "their trustworthiness. Moreover, users with mal-\n",
      "intent often post fake reviews (FR) to mislead cus-\n",
      "tomers by promoting or demoting products or tar-\n",
      "get stores. Authors of FR can sway customer\n",
      "choices towards companies with which they are\n",
      "associated, or against competitors making fake re-\n",
      "views a lucrative business. There has been an in-\n",
      "crease in FR profusion lately. According to the\n",
      "report of the Harvard Business School (Luca and\n",
      "Zervas, 2016) the percentage of fake reviews on\n",
      "YELP1 increased from 5 % in 2006 to 20% in\n",
      "2013. This makes FR detection an important chal-\n",
      "lenge to be addressed.\n",
      "FR were ﬁrstly categorized by Jindal et al.\n",
      "(2008) into three groups: (1) Untruthful opin-\n",
      "ions: mislead readers by giving positive reviews\n",
      "to promote or demote target object, (2) Reviews\n",
      "on brands only: the reviewer focus on the brands,\n",
      "producers or sellers of a product or service without\n",
      "commenting on the product or service, (3) Non-\n",
      "to promote or demote target object, (2) Reviews\n",
      "on brands only: the reviewer focus on the brands,\n",
      "producers or sellers of a product or service without\n",
      "commenting on the product or service, (3) Non-\n",
      "reviews: the reviews are irrelevant to the product\n",
      "and do not contain opinions but advertisements or\n",
      "questions. The ﬁrst category is the most challeng-\n",
      "ing type to detect, and that is the focus of our pa-\n",
      "per. Given the large numbers of reviews posted\n",
      "daily, automatic methods would be preferred over\n",
      "manual ones as illustrated in (Ott et al., 2011). Re-\n",
      "cent years have witnessed an increased impetus on\n",
      "machine learning methods for data-driven FR de-\n",
      "tection (Mukherjee et al., 2013; Ott et al., 2011;\n",
      "Rout et al., 2017)\n",
      "The performance of machine learning mod-\n",
      "els for detecting FR is heavily inﬂuenced by the\n",
      "data representation (or features) in their applica-\n",
      "tion (Bengio et al., 2013). Text analytics has\n",
      "conventionally focused on domains such as la-\n",
      "belling news stories or grouping disease reports\n",
      "based on severity where the human authors of\n",
      "text documents are largely passive to the usage\n",
      "of downstream analytics. FR mitigation meth-\n",
      "ods, on the other hand, are in direct conﬂict with\n",
      "the intents of FR peddlers, generating interest-\n",
      "1https://www.yelp.co.uk/\n",
      "751\n",
      "ing gamiﬁcation dynamics. This makes it impor-\n",
      "tant for data-driven FR solutions to rely on more\n",
      "generic or higher-level data representations rather\n",
      "than simple lexical ones based on words, phrases\n",
      "and sentences. This is because FR ﬁlters using\n",
      "higher-level generic features may naturally be ex-\n",
      "pected to be more robust and resistant to sim-\n",
      "ple workarounds by FR authors such as word and\n",
      "phrase replacements. Further, higher-level fea-\n",
      "tures may have limited volatility across domains;\n",
      "thus, FR detection methods based on them may be\n",
      "more transferable across domains.\n",
      "In this paper, we evaluate the effectiveness of\n",
      "emotion and sentiment based representations for\n",
      "the task of building machine learning models for\n",
      "FR detection. In particular, we illustrate that im-\n",
      "proved data representations can be achieved by\n",
      "leveraging a plurality of emotion and sentiment\n",
      "extraction methods, as well as by estimating emo-\n",
      "tions and sentiments on a part-by-part basis by\n",
      "segmenting the reviews. We illustrate the im-\n",
      "proved effectiveness of multiple emotion and sen-\n",
      "timent features as well as review-segmented fea-\n",
      "tures by evaluating over real-world datasets.\n",
      "2 Related Work\n",
      "Representation learning focuses on developing a\n",
      "more instructive feature set for training a classi-\n",
      "ﬁcation model that helps to boost the FR detec-\n",
      "tion process (Li et al., 2017; Yilmaz and Durahim,\n",
      "2018). Within past research, diverse features se-\n",
      "lection methods have been employed to detect FR.\n",
      "ﬁcation model that helps to boost the FR detec-\n",
      "tion process (Li et al., 2017; Yilmaz and Durahim,\n",
      "2018). Within past research, diverse features se-\n",
      "lection methods have been employed to detect FR.\n",
      "These may be divided into two classes: review-\n",
      "centric and reviewer-centric features. Reviewer-\n",
      "centric features are related to the reviewer’s be-\n",
      "haviour (Fontanarava et al., 2017) rather than\n",
      "the review itself. Those features include tex-\n",
      "tual features, rating features, and temporal fea-\n",
      "tures. Review-centric features are derived from\n",
      "the content of a review. Commonly used review-\n",
      "centric features include Bag-of-words, TF-IDF\n",
      "(Term-frequency inverse-document- frequency),\n",
      "POS (part of speech) tags, word n-grams (Ahmed\n",
      "et al., 2018), and word embedding vectors (e.g.\n",
      "Word2vec, Doc2vec) (Krishnamurthy et al., 2018;\n",
      "Yilmaz and Durahim, 2018). A recent study by Jia\n",
      "et al. (2018) explored the application of linguis-\n",
      "tic features to distinguish between fake and non-\n",
      "fake reviews. They used Yelp ﬁlter dataset in their\n",
      "study and applied Term Frequency, Word2vec, and\n",
      "Latent Topic Distribution for data representation.\n",
      "They trained three machine learning models i.e.\n",
      "SVM, Logistic Regression, and Multi-layer Per-\n",
      "ceptron and found that LDA+Logistic Regression\n",
      "and LDA+Multi-layer Perceptron performed bet-\n",
      "ter with 81.3% of accuracy.\n",
      "With representations being only a means to en-\n",
      "able better FR identiﬁcation, it is useful to brieﬂy\n",
      "outline the classiﬁcation techniques that have been\n",
      "ter with 81.3% of accuracy.\n",
      "With representations being only a means to en-\n",
      "able better FR identiﬁcation, it is useful to brieﬂy\n",
      "outline the classiﬁcation techniques that have been\n",
      "employed for FR detection. Ott et al., (2011) used\n",
      "word n-gram features in combination with a SVM\n",
      "classiﬁer. Banerjee and Chua (2014) employed a\n",
      "Logistic Regression classiﬁer over POS tags and\n",
      "writing style features (e.g., tense of words) for\n",
      "FR detection. Algur et al., (2010) explored a\n",
      "similarity-oriented method for FR detection over\n",
      "domain-speciﬁc product features.\n",
      "As mentioned earlier, our representations are\n",
      "centred on emotion and sentiment based features.\n",
      "There has been very little prior work on using such\n",
      "features for FR detection. An early work in senti-\n",
      "ment analysis for FR detection was conducted by\n",
      "Peng and Zhong (2014), whereas (K et al., 2019)\n",
      "explore utility of emotions in health fake news de-\n",
      "tection. Peng and Zhong (2014) chose SentiWord-\n",
      "Net and MPQA lexicons and analysed sentiment\n",
      "on review and product features. In our experiment,\n",
      "we used IBM, Aﬁnn, SenticNet, and Biu Liu lexi-\n",
      "cons. To our knowledge, this is the ﬁrst study de-\n",
      "tecting FR by means of combination emotion and\n",
      "sentiment analysis. Taking cue from the previous\n",
      "work of FR detection, we use Random Forest clas-\n",
      "siﬁer, in our experiments.\n",
      "3 Methodology\n",
      "In this section we describe our proposed approach\n",
      "to online FR detection using emotion and senti-\n",
      "ment based text representation.\n",
      "3.1 Emotion and Sentiment Analysis\n",
      "3 Methodology\n",
      "In this section we describe our proposed approach\n",
      "to online FR detection using emotion and senti-\n",
      "ment based text representation.\n",
      "3.1 Emotion and Sentiment Analysis\n",
      "For the purpose of sentiment and emotion anal-\n",
      "ysis, we apply three different sentiment lexicons\n",
      "and one emotion analysis API.\n",
      "•IBM Watson Natural Language Understand-\n",
      "ing. Natural Language Understanding (NLU) 2\n",
      "is a collection of APIs that offer text analy-\n",
      "sis through natural language processing. One\n",
      "of the feature of IBM Watson NLU is emo-\n",
      "tion analysis. The API takes a text as\n",
      "an input and returns the category which the\n",
      "2https://www.ibm.com/services/natural-language-\n",
      "understanding/\n",
      "752\n",
      "text belongs to, stored in a list variable: <\n",
      "KeyV aluePair < String, Double >>e.g.\n",
      "”emotion” : {”sadness”:0.336228}. Each item\n",
      "in the list contains the category (emotion) name\n",
      "and the categorization score. IBM Watson NLU\n",
      "can detect ﬁve emotions: anger, disgust, fear,\n",
      "joy, and sadness. For example, for an an input ’I\n",
      "love apples! I don’t like oranges’, the NLU API\n",
      "returns (sadness: 0.32665, joy: 0.563273, fear:\n",
      "0.033387, disgust: 0.022637, anger: 0.041796).\n",
      "•SenticNet lexicon. SenticNet3 performs tasks\n",
      "such as polarity detection and emotion recog-\n",
      "nition. Instead of merely relying on word co-\n",
      "occurrence frequencies, it leverages semantics\n",
      "and linguistics. This lexicon contains a list of\n",
      "words with their polarity and intensity values.\n",
      "The intensity is a ﬂoat number between -1 and\n",
      "+1. For example, according to the SenticNet\n",
      "lexicon ’abandoned’ is a negative word with in-\n",
      "tensity of -0.85. Each word in the lexicon is\n",
      "assigned with only one polarity and intensity\n",
      "value.\n",
      "•AFINN lexicon. AFINN4 lexicon is a list of\n",
      "English terms rated with valence on a scale -5\n",
      "(negative) and +5 (positive). This lexicon has\n",
      "been manually labelled by Finn ˚Arup Nielsen\n",
      "(2011). AFINN provides two versions of lexi-\n",
      "con: the newest version AFINN-111 with 2477\n",
      "words and phrases and AFINN-96 with 1468\n",
      "unique words and phrases on 1480 lines. Our\n",
      "experiment use AFINN-111 as it is the most up-\n",
      "to-date version.\n",
      "•Biu Liu lexicon. Biu Liu5 lexicon consists of\n",
      "6789 words including 2006 positive and 4783\n",
      "unique words and phrases on 1480 lines. Our\n",
      "experiment use AFINN-111 as it is the most up-\n",
      "to-date version.\n",
      "•Biu Liu lexicon. Biu Liu5 lexicon consists of\n",
      "6789 words including 2006 positive and 4783\n",
      "negative words (Hu and Liu, 2004). This lexi-\n",
      "con does not provide any sentiment scores and\n",
      "only provides positive/negative labels.\n",
      "3.2 Representation Learning\n",
      "In this work we explore whether sentiment and\n",
      "emotions extracted from a review can be used to\n",
      "train machine learning models for distinguishing\n",
      "between fake and non-fake reviews. We perform\n",
      "the sentiment/emotion analysis with different lev-\n",
      "els of granularity on a part-by-part basis by seg-\n",
      "menting the reviews.\n",
      "3https://sentic.net/\n",
      "4https://pypi.org/project/aﬁnn/\n",
      "5http://www.cs.uic.edu/˜liub/FBS/opinion-lexicon-\n",
      "English.rar\n",
      "3.2.1 Sentiment Based Representation\n",
      "The process of constructing sentiment based rep-\n",
      "resentation of a review is presented in Algorithm\n",
      "1. We ﬁrst split a review into P segments,\n",
      "each one containing the same number of sen-\n",
      "tences. For example, if P=4, then we split a\n",
      "review into 4 segments. For each segment we\n",
      "identify all positive and all negative words us-\n",
      "ing the lexicons. In the next step, all positive\n",
      "sentiment values and all negative sentiment val-\n",
      "ues within the segment are accumulated together.\n",
      "In the case of AFINN and SenticNet, all posi-\n",
      "tive and negative values are summed in each seg-\n",
      "ment. For Biu Liu lexicon, all positive and all\n",
      "negative words are counted. Following this, the\n",
      "In the case of AFINN and SenticNet, all posi-\n",
      "tive and negative values are summed in each seg-\n",
      "ment. For Biu Liu lexicon, all positive and all\n",
      "negative words are counted. Following this, the\n",
      "segment is represented by a two dimensional vec-\n",
      "tor [pos(si), neg(si)], where pos(si) and neg(si)\n",
      "represent the accumulated/counted positive and\n",
      "negative sentiment values. Finally, all P vec-\n",
      "tors (one generated for each segment) are concate-\n",
      "nated. The concatenated vector is returned as the\n",
      "sentiment representation of the entire review. The\n",
      "process looks the same for all sentiment lexicons.\n",
      "Algorithm 1Sentiment Based Representation\n",
      "Input: Review R, number of segments P, senti-\n",
      "ment lexicon L\n",
      "Output: Sentiment representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Tokenise si into set of words W\n",
      "4: Retrieve sentiment values for all words in\n",
      "W using L\n",
      "5: Accumulate all positive sentiment values in\n",
      "W as pos(si)\n",
      "6: Accumulate all negative sentiment values in\n",
      "W as neg(si)\n",
      "7: vi = [pos(si), neg(si)]\n",
      "8: end for\n",
      "9: v(R) := [v1, . . . , vP ]\n",
      "10: return v(R)\n",
      "3.2.2 Emotion Based Representation\n",
      "The process of generating emotion based repre-\n",
      "sentation is presented in Algorithm 2. As in the\n",
      "case of the sentiment based representation, a re-\n",
      "view is ﬁrst divided in P segments. All sentences\n",
      "in each segment is then passed to the IBM Watson\n",
      "API. As the output we obtain vector with the ﬁve\n",
      "emotions’ scores. Finally, the emotion vectors ob-\n",
      "view is ﬁrst divided in P segments. All sentences\n",
      "in each segment is then passed to the IBM Watson\n",
      "API. As the output we obtain vector with the ﬁve\n",
      "emotions’ scores. Finally, the emotion vectors ob-\n",
      "tained for all the segments are concatenated. The\n",
      "753\n",
      "output vector is returned as the emotion represen-\n",
      "tation of the entire review.\n",
      "Algorithm 2Emotion based Representation\n",
      "Input: Review R, number of segments P, emo-\n",
      "tion lexicon L\n",
      "Output: Emotion representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Get vector vi with emotions scores from L\n",
      "4: end for\n",
      "5: v(R) := [v1, . . . , vP ]\n",
      "6: return v(R)\n",
      "3.2.3 Multi-Segment Based Representation\n",
      "The process of multi-segment representation\n",
      "learning is presented in Algorithm 3. With this\n",
      "technique, the sentiment/emotion based represen-\n",
      "tation is ﬁrst generated for different numbers of\n",
      "segments 1 . . . P. Following this, all vectors ob-\n",
      "tained for p = 1. . . Pare concatenated to form the\n",
      "ﬁnal representation. In this way, the output vector\n",
      "contains more granular information on the distri-\n",
      "bution of sentiment or emotions within a review.\n",
      "Algorithm 3Multi-Segment Representation\n",
      "Input: Review R, maximum number of segments\n",
      "P, lexicon L\n",
      "Output: Vector representation of R\n",
      "1: for allp ∈1 . . . Pdo\n",
      "2: Obtain vp(R) calling Algorithm 1 or 2 and\n",
      "passing R, p and L as parameters\n",
      "3: end for\n",
      "4: v(R) := [v1(R), . . . , vP (R)]\n",
      "5: return v(R)\n",
      "3.2.4 Combined Sentiment and Emotion\n",
      "Based Representation\n",
      "The last representation type that we explore is the\n",
      "combined sentiment and emotion based represen-\n",
      "tation. The process is presented in Algorithm 4.\n",
      "First, a review is divided into P segments. The\n",
      "representation of each segment is generated by\n",
      "combined sentiment and emotion based represen-\n",
      "tation. The process is presented in Algorithm 4.\n",
      "First, a review is divided into P segments. The\n",
      "representation of each segment is generated by\n",
      "concatenation of sentiment and emotion represen-\n",
      "tations obtained with Algorithms 1 and 2 respec-\n",
      "tively. Finally, representations of all segments are\n",
      "merged together.\n",
      "Algorithm 4 Combined sentiment and Emotion\n",
      "Based Representation\n",
      "Input: Review R, number of segments P, senti-\n",
      "ment lexicon Ls, emotion lexicon Le\n",
      "Output: Vector representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Get sentiment representation Vs(R) apply-\n",
      "ing Algorithm 1 with R, P and Ls\n",
      "4: Get emotion representation Ve(R) applying\n",
      "Algorithm 2 with R, P and Le\n",
      "5: vi = [Vs(R), Ve(R)]\n",
      "6: end for\n",
      "7: v(R) := [v1, . . . , vP ]\n",
      "8: return v(R)\n",
      "4 Experimental Results and Discussion\n",
      "In this section we present the experimental\n",
      "evaluation of the proposed four different senti-\n",
      "ment/emotion based representations. Each of the\n",
      "representations are separetely used to build a ma-\n",
      "chine learning model for FR detection. We con-\n",
      "ducted an extensive set of experiments in order to\n",
      "answer the following key questions:\n",
      "•Do sentiment/emotion based representations\n",
      "help in FR detection?\n",
      "•Which of the proposed representations is the\n",
      "most effective for FR detection?\n",
      "•Can higher sentiment/emotion granularity level\n",
      "improve the data representation?\n",
      "4.1 Experimental Setup\n",
      "•Which of the proposed representations is the\n",
      "most effective for FR detection?\n",
      "•Can higher sentiment/emotion granularity level\n",
      "improve the data representation?\n",
      "4.1 Experimental Setup\n",
      "Datasets. We collected our datasets from two\n",
      "different sources. We used gold standard spam\n",
      "review dataset from Ott et al., (2011), and Yelp\n",
      "dataset from Rayana and Akoglu (2015). The Ott\n",
      "dataset contains reviews about hotels. Yelp Zip\n",
      "and Yelp NYC are extracted from Yelp ﬁltered\n",
      "dataset. Yelp NYC is a collection of reviews from\n",
      "restaurants located in New York City (NYC) while\n",
      "Yelp Zip is a collection of restaurant’s reviews in\n",
      "zip code area in NY State. Each of the datasets\n",
      "contains true labels of the reviews, i.e. fake or\n",
      "non-fake label assigned to each review. Table 1\n",
      "shows the size and class distribution for each of\n",
      "the datasets. In our experiment, we only con-\n",
      "sider reviews that contain more than 10 sentences.\n",
      "We presume that proposed representation learning\n",
      "techniques would not be effective for short reviews\n",
      "754\n",
      "since sparse text does not allow to identify emo-\n",
      "tions and sentiments well. Table 2 demonstrates\n",
      "the statistics of the datasets after ﬁltering.\n",
      "Dataset Non-fake Fake\n",
      "YELP ZIP 528019 80439\n",
      "YELP NYC 322097 36860\n",
      "Ott 800 800\n",
      "Table 1: Statistics of the datasets\n",
      "Dataset Non-fake Fake\n",
      "YELP ZIP 170261 15108\n",
      "YELP NYC 105080 6185\n",
      "Ott 340 270\n",
      "Table 2: Statistics of the datasets after ﬁltering\n",
      "Learning. As the machine learning algorithm we\n",
      "used Random Forest (RF) given that it was re-\n",
      "ported as one of the most effective in FR detection\n",
      "(Chowdhary and Pandit, 2018; Saumya and Singh,\n",
      "2018; Viviani and Pasi, 2017). However, any other\n",
      "learning algorithm can be applied instead. We set\n",
      "n estimator=100 and random state=42 for the RF\n",
      "parameter. All the experiments are performed with\n",
      "5-fold cross-validation and the prediction perfor-\n",
      "mance is evaluated with application of F-measure.\n",
      "Given the very high class imbalance in the Yelp\n",
      "NYC and Yelp Zip, we randomly select number\n",
      "of non-fake reviews equal to the number of FR in\n",
      "order to balance the training data.\n",
      "4.2 Sentiment and Emotion Granularity\n",
      "In this section we investigate what level of gran-\n",
      "ularity in terms of sentiment and emotion is the\n",
      "most representative for FR detection. Tables 3-5\n",
      "demonstrate the F-measure obtained by RF with\n",
      "each of the datasets and sentiment and emotion\n",
      "based representations for reviews. For the param-\n",
      "eter P we used values from 1 to 4. For each ta-\n",
      "ble, the ﬁrst row represents results obtained by RF\n",
      "each of the datasets and sentiment and emotion\n",
      "based representations for reviews. For the param-\n",
      "eter P we used values from 1 to 4. For each ta-\n",
      "ble, the ﬁrst row represents results obtained by RF\n",
      "applied with the emotion based representation ob-\n",
      "tained with the IBM Watson API. The three bot-\n",
      "tom columns contain results obtained for the sen-\n",
      "timent based representation generated with each of\n",
      "the three sentiment lexicons. Each column refers\n",
      "to a different value of parameter P = 1×4. The\n",
      "last column presents results obtained for multi-\n",
      "segment based representation.\n",
      "We can observe from the tables that in the ma-\n",
      "jority of cases, the higher the granularity ( P) the\n",
      "better the prediction performance. It can also be\n",
      "noted that the multi-segment based representation\n",
      "tends to perform better than when a single segmen-\n",
      "tation is applied. The only exception is the Biu Liu\n",
      "lexicon, which for Yelp, Zip, and Ott obtained the\n",
      "best results for P = 1.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.570 0.584 0.589 0.584 0.597\n",
      "SenticNet 0.506 0.510 0.522 0.523 0.524\n",
      "Biu Liu 0.574 0.540 0.547 0.558 0.557\n",
      "AFINN 0.550 0.542 0.549 0.555 0.563\n",
      "Table 3: RF’s F-measure over Yelp ZIP dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.554 0.569 0.578 0.569 0.584\n",
      "SenticNet 0.511 0.520 0.523 0.525 0.526\n",
      "Biu Liu 0.546 0.523 0.543 0.543 0.555\n",
      "AFINN 0.524 0.529 0.541 0.544 0.557\n",
      "Table 4: RF’s F-measure over Yelp NYC dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.620 0.605 0.543 0.533 0.590\n",
      "SenticNet 0.533 0.529 0.483 0.525 0.570\n",
      "AFINN 0.524 0.529 0.541 0.544 0.557\n",
      "Table 4: RF’s F-measure over Yelp NYC dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.620 0.605 0.543 0.533 0.590\n",
      "SenticNet 0.533 0.529 0.483 0.525 0.570\n",
      "Biu Liu 0.618 0.561 0.592 0.576 0.600\n",
      "AFINN 0.523 0.560 0.580 0.545 0.600\n",
      "Table 5: RF’s F-measure over Ott dataset.\n",
      "4.3 Sentiment vs. Emotion\n",
      "In this section we compare the results obtained by\n",
      "RF applied with the sentiment and the emotion\n",
      "based representations of data. We can see from\n",
      "Tables 3-5 that IBM emotion lexicon obtained the\n",
      "best performance in comparison to the three senti-\n",
      "ment lexicons in the Yelp Zip and NYC datasets.\n",
      "This may be considered unsurprising since emo-\n",
      "tions provide more ﬁne grained information for the\n",
      "classiﬁers to work with. For the Ott dataset, Biu\n",
      "Liu and AFINN lexicon obtained better results for\n",
      "some of the greater values of P.\n",
      "In order to perform better comparison be-\n",
      "tween the sentiment and emotion based rep-\n",
      "resentations we calculated average of the re-\n",
      "sults obtained for each of the granularity levels:\n",
      "P1, P2, P3, P4, P1 −4. The results are demon-\n",
      "strated in Figure 1. We can observe from the\n",
      "graphs that the IBM emotion lexicon performs sig-\n",
      "niﬁcantly better than any of the other sentiment\n",
      "lexicons apart from the Ott dataset where it is out-\n",
      "performed by the Biu Liu lexicon.\n",
      "755\n",
      "Figure 1: Average F-measure obtained for all val-\n",
      "ues of P\n",
      "4.4 Combined Sentiment and Emotion Based\n",
      "Representation\n",
      "Table 6 demonstrates results obtained for the com-\n",
      "bined sentiment and emotion based representation\n",
      "generated according to the Algorithm 4. We can\n",
      "observe that for Zip and NYC datasets the best\n",
      "results were obtained when multi-segment based\n",
      "representation was applied. With Ott the best per-\n",
      "formance was obtained for P1.\n",
      "Dataset P1 P2 P3 P4 P1-4\n",
      "ZIP 0.589 0.596 0.599 0.599 0.602\n",
      "NYC 0.580 0.580 0.589 0.584 0.588\n",
      "Ott 0.653 0.624 0.606 0.604 0.640\n",
      "Table 6: F-measure obtained with combined sen-\n",
      "timent and emotion representation learning.\n",
      "In Figures 2-4 we compare the performance of\n",
      "the combined sentiment and emotion based repre-\n",
      "sentation with the emotion based representation,\n",
      "which so far obtained the most promising results.\n",
      "We can observe that the combined approach ob-\n",
      "tained better results in each case, with the dif-\n",
      "ference in F-measure being quite signiﬁcant for\n",
      "Zip and NYC datasets. This demonstrate that im-\n",
      "proved data representation can be achieved by ap-\n",
      "plying combination of different emotion and sen-\n",
      "timent extraction methods.\n",
      "5 Conclusions and Future Work\n",
      "In this paper, we analyzed the effectiveness of\n",
      "emotion and sentiment based representations esti-\n",
      "mated over varying text grabularities, for the task\n",
      "of fake review classiﬁcation. Through an em-\n",
      "pirical study across three real-world datasets, we\n",
      "ﬁnd consistent evidence that combinations of emo-\n",
      "mated over varying text grabularities, for the task\n",
      "of fake review classiﬁcation. Through an em-\n",
      "pirical study across three real-world datasets, we\n",
      "ﬁnd consistent evidence that combinations of emo-\n",
      "tions and sentiments work better than either of\n",
      "Figure 2: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for Zip\n",
      "Figure 3: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for NYC\n",
      "Figure 4: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for Ott\n",
      "them separately. Further, we observe that com-\n",
      "bining emotion and sentiment representations ob-\n",
      "tained across different text granularities yields bet-\n",
      "ter accuracies over the restaurant review datasets.\n",
      "As future work, we plan to carry on research\n",
      "on cross domain between different datasets. We\n",
      "also want to observe how sentiment and emotion\n",
      "work on neural network model such as CNN and\n",
      "LSTM using generic as well as custom-built lexi-\n",
      "cons (Bandhakavi et al., 2017).\n",
      "756\n",
      "   \n",
      "Acknowledgments \n",
      "The authors thank LPDP (Indonesia Endowment \n",
      "Fund for Education) for funding this research.  \n",
      " \n",
      "References  \n",
      "Ahmed, Hadeer, et al. “Detecting Opinion Spams and \n",
      "Fake News Using Text Classification.” Security \n",
      "and Privacy , vol. 1, no. 1, 2017, p. e9, \n",
      "doi:10.1002/spy2.9. \n",
      "Algur, Siddu P., et al. “Conceptual Level Similarity \n",
      "Measure Based Review Spam Detection.” \n",
      "Proceedings of the 2010 International \n",
      "Conference on Signal and Image Processing, \n",
      "ICSIP 2010 , IEEE, 2010, pp. 416 –23, \n",
      "doi:10.1109/ICSIP.2010.5697509. \n",
      "Anoop, K., et al. “Emotion Cognizance Improves Fake \n",
      "News Identification.” ArXiv Preprint \n",
      "ArXiv:1906.10365, 2019. \n",
      "Bandhakavi, Anil, et al. “Lexicon Generation for \n",
      "Emotion Detection from Text.” IEEE Intelligent \n",
      "Systems, vol. 32, no. 1, IEEE, 2017, pp. 102 –08, \n",
      "doi:10.1109/MIS.2017.22. \n",
      "Banerjee, Snehasish, and Alton Y. K. Chua. \n",
      "“Applauses in Hotel Reviews: Genuine or \n",
      "Deceptive?” Proceedings of 2014 Science and \n",
      "Information Conference, SAI 2014 , The Science \n",
      "and Information (SAI) Organization, 2014, pp. \n",
      "938–42, doi:10.1109/SAI.2014.6918299. \n",
      "Bengio, Yoshua, et al. “Representation Learning: A \n",
      "Review and New Perspectives. ” IEEE \n",
      "Transactions on Pattern Analysis and Machine \n",
      "Intelligence, vol. 35, no. 8, IEEE, 2013, pp. \n",
      "1798–828. \n",
      "Chowdhary, Neha S., and Anala A. Pandit. “Fake \n",
      "Review Detection Using Classification.” \n",
      "International Journal of Computer Applications, \n",
      "vol. 180, no. 50, 2018, pp. 16–21.\n",
      "1798–828. \n",
      "Chowdhary, Neha S., and Anala A. Pandit. “Fake \n",
      "Review Detection Using Classification.” \n",
      "International Journal of Computer Applications, \n",
      "vol. 180, no. 50, 2018, pp. 16–21. \n",
      "Fontanarava, Julien, et al. “Feature Analysis for Fake \n",
      "Review Detection through Supervised \n",
      "Classification.” 2017 IEEE International \n",
      "Conference on Data Science and Advanced \n",
      "Analytics (DSAA), IEEE, 2017, pp. 658–66. \n",
      "Hu, Minqing, and Bing Liu. “Mining and Summarizing \n",
      "Customer Reviews.” Proceedings of the Tenth \n",
      "ACM SIGKDD International Conference on \n",
      "Knowledge Discovery and Data Mining, vol. 50, \n",
      "no. 08, 2004, pp. 50 -4466-50–4466, \n",
      "doi:10.5860/choice.50-4466. \n",
      "Jia, Shaohua, et al. “Fake Reviews Detection Based on \n",
      "LDA.” 2018 4th International Conference on \n",
      "Information Management, ICIM 2018 , IEEE, \n",
      "2018, pp. 280 –83, \n",
      "doi:10.1109/INFOMAN.2018.8392850. \n",
      "Jindal, Nitin, and Bing Liu. “Opinion Spam and \n",
      "Analysis.” Proceedings of the 2008 International \n",
      "Conference on Web Search and Data Mining , \n",
      "ACM, 2008, pp. 219–30. \n",
      "Krishnamurthy, Gangeshwar, et al. “A Deep Learning \n",
      "Approach for Multimodal Deception Detection.” \n",
      "ArXiv Preprint ArXiv:1803.00344, 2018. \n",
      "Kumar, Abhinav, et al. “Spotting Opinion Spammers \n",
      "Using Be havioral Footprints.” Proceedings of \n",
      "the 19th ACM SIGKDD International \n",
      "Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam\n",
      "Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam \n",
      "Review Detection.” Neurocomputing, vol. 254, \n",
      "Elsevier B.V., 2017, pp. 1339 –51, \n",
      "doi:10.1016/j.neucom.2016.10.080. \n",
      "Luca, Michael, and Georgios Zervas. “Fake It till You \n",
      "Make It: Reputation.” Competition, and Yelp \n",
      "Review Fraud., SSRN Electronic Journal, 2016. \n",
      "Nielsen, Finn Årup. “A New ANEW: Evaluation of a \n",
      "Word List for Sentiment Analysis in \n",
      "Microblogs.” CEUR Workshop Proceedings , \n",
      "vol. 718, 2011, pp. 93 –98, \n",
      "doi:10.1016/j.knosys.2015.06.015. \n",
      "Ott, Myle, et al. “Finding Deceptive Opinion Spam by \n",
      "Any Stretch of the Imagination.” Proceedings of \n",
      "the 49th Annual Meeting of the Association for \n",
      "Computational Linguistics: Human Language \n",
      "Technologies-Volume 1 , Association for \n",
      "Computational Linguistics, 2011, pp. 309–19. \n",
      "Peng, Qingxi, and Ming Zhong. “Detecting Spam \n",
      "Review through Sentiment AnalysisPeng, Q. and \n",
      "Zhong, M. (2014) ‘Detecting Spam Review \n",
      "through Sentiment Analysis’, Journal of \n",
      "Software. Doi: 10.4304/Jsw.9.8.2065 -2072.” \n",
      "Journal of Software , 2014, \n",
      "doi:10.4304/jsw.9.8.2065-2072. \n",
      "Rayana, Shebuti. “Collective Opinion Spam  \n",
      "Detection : Bridging Review Networks and \n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no.\n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no. \n",
      "3, Multimedia Tools and Applications, 2017, pp. \n",
      "3187–211, doi:10.1007/s11042-016-3819-y.\n",
      "757\n",
      "   \n",
      "Saumya, Sunil, and Jyoti Prakash Singh. “Detection of \n",
      "Spam Reviews: A Sentiment Analysis \n",
      "Approach.” CSI Transactions on ICT, vol. 6, no. \n",
      "2, Springer, 2018, pp. 137–48. \n",
      "Viviani, Marco, and Gabriella Pasi. “Quantifier Guided \n",
      "Aggregation for the Veracity Assessment of \n",
      "Online Reviews.” International Journal of \n",
      "Intelligent Systems, vol. 32, no. 5, Wiley Online \n",
      "Library, 2017, pp. 481–501. \n",
      "Yilmaz, Cennet Merve, and Ahmet Onur Durahim. \n",
      "“SPR2EP: A S emi-Supervised Spam Review \n",
      "Detection Framework.” Proceedings of the 2018 \n",
      "IEEE/ACM International Conference on \n",
      "Advances in Social Networks Analysis and \n",
      "Mining, ASONAM 2018 , 2018, pp. 306 –13, \n",
      "doi:10.1109/ASONAM.2018.8508314.\n"
     ]
    }
   ],
   "source": [
    "# Access all stored documents\n",
    "docs = vectorstore._collection.get()\n",
    "for doc in docs['documents']:\n",
    "    print(doc)  # Each doc is a chunk of text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\n",
      "Varna, Bulgaria, Sep 2–4, 2019.\n",
      "https://doi.org/10.26615/978-954-452-056-4_087\n",
      "750\n",
      "Sentiment and Emotion Based Text\n",
      "Representation for Fake Reviews Detection\n",
      "Alimuddin Melleng\n",
      "Queen’s University Belfast\n",
      "amelleng01@qub.ac.uk\n",
      "Anna-Jurek Loughrey\n",
      "Queen’s University Belfast\n",
      "a.jurek@qub.ac.uk\n",
      "Deepak P\n",
      "Queen’s University Belfast\n",
      "deepaksp@acm.org\n",
      "Abstract\n",
      "Fake reviews are increasingly prevalent\n",
      "across the Internet. They can be uneth-\n",
      "ical and harmful. They can affect busi-\n",
      "nesses and mislead customers. As opin-\n",
      "ions on the Web are increasingly relied on,\n",
      "the detection of fake reviews has become\n",
      "more critical. In this study we explore\n",
      "the effectiveness of sentiment and emo-\n",
      "tions based representations for the task\n",
      "of building machine learning models for\n",
      "fake reviews detection. The experiment\n",
      "performed with three real-world datasets\n",
      "demonstrate that improved data represen-\n",
      "tation can be achieved by combining sen-\n",
      "timent and emotion extraction methods, as\n",
      "well as by performing sentiment and emo-\n",
      "tion analysis on a part-by-part basis by\n",
      "segmenting the reviews.\n",
      "1 Introduction\n",
      "The Internet has evolved into a content creation\n",
      "platform where people express their opinions and\n",
      "experiences. Online reviews written by users have\n",
      "signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n",
      "Metadata: {'page': 0, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n",
      "periences, particularly in making choices on pur-\n",
      "chasing products or services. At the same time,\n",
      "companies need reviews on their products or ser-\n",
      "vices in order to get feedback and maintain good\n",
      "reputation. However, not all reviews available in\n",
      "the Internet are genuine. Profusion of reviews\n",
      "of questionable quality increase concerns about\n",
      "their trustworthiness. Moreover, users with mal-\n",
      "intent often post fake reviews (FR) to mislead cus-\n",
      "tomers by promoting or demoting products or tar-\n",
      "get stores. Authors of FR can sway customer\n",
      "choices towards companies with which they are\n",
      "associated, or against competitors making fake re-\n",
      "views a lucrative business. There has been an in-\n",
      "crease in FR profusion lately. According to the\n",
      "report of the Harvard Business School (Luca and\n",
      "Zervas, 2016) the percentage of fake reviews on\n",
      "YELP1 increased from 5 % in 2006 to 20% in\n",
      "2013. This makes FR detection an important chal-\n",
      "lenge to be addressed.\n",
      "FR were ﬁrstly categorized by Jindal et al.\n",
      "(2008) into three groups: (1) Untruthful opin-\n",
      "ions: mislead readers by giving positive reviews\n",
      "to promote or demote target object, (2) Reviews\n",
      "on brands only: the reviewer focus on the brands,\n",
      "producers or sellers of a product or service without\n",
      "commenting on the product or service, (3) Non-\n",
      "Metadata: {'page': 0, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: to promote or demote target object, (2) Reviews\n",
      "on brands only: the reviewer focus on the brands,\n",
      "producers or sellers of a product or service without\n",
      "commenting on the product or service, (3) Non-\n",
      "reviews: the reviews are irrelevant to the product\n",
      "and do not contain opinions but advertisements or\n",
      "questions. The ﬁrst category is the most challeng-\n",
      "ing type to detect, and that is the focus of our pa-\n",
      "per. Given the large numbers of reviews posted\n",
      "daily, automatic methods would be preferred over\n",
      "manual ones as illustrated in (Ott et al., 2011). Re-\n",
      "cent years have witnessed an increased impetus on\n",
      "machine learning methods for data-driven FR de-\n",
      "tection (Mukherjee et al., 2013; Ott et al., 2011;\n",
      "Rout et al., 2017)\n",
      "The performance of machine learning mod-\n",
      "els for detecting FR is heavily inﬂuenced by the\n",
      "data representation (or features) in their applica-\n",
      "tion (Bengio et al., 2013). Text analytics has\n",
      "conventionally focused on domains such as la-\n",
      "belling news stories or grouping disease reports\n",
      "based on severity where the human authors of\n",
      "text documents are largely passive to the usage\n",
      "of downstream analytics. FR mitigation meth-\n",
      "ods, on the other hand, are in direct conﬂict with\n",
      "the intents of FR peddlers, generating interest-\n",
      "1https://www.yelp.co.uk/\n",
      "Metadata: {'page': 0, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 751\n",
      "ing gamiﬁcation dynamics. This makes it impor-\n",
      "tant for data-driven FR solutions to rely on more\n",
      "generic or higher-level data representations rather\n",
      "than simple lexical ones based on words, phrases\n",
      "and sentences. This is because FR ﬁlters using\n",
      "higher-level generic features may naturally be ex-\n",
      "pected to be more robust and resistant to sim-\n",
      "ple workarounds by FR authors such as word and\n",
      "phrase replacements. Further, higher-level fea-\n",
      "tures may have limited volatility across domains;\n",
      "thus, FR detection methods based on them may be\n",
      "more transferable across domains.\n",
      "In this paper, we evaluate the effectiveness of\n",
      "emotion and sentiment based representations for\n",
      "the task of building machine learning models for\n",
      "FR detection. In particular, we illustrate that im-\n",
      "proved data representations can be achieved by\n",
      "leveraging a plurality of emotion and sentiment\n",
      "extraction methods, as well as by estimating emo-\n",
      "tions and sentiments on a part-by-part basis by\n",
      "segmenting the reviews. We illustrate the im-\n",
      "proved effectiveness of multiple emotion and sen-\n",
      "timent features as well as review-segmented fea-\n",
      "tures by evaluating over real-world datasets.\n",
      "2 Related Work\n",
      "Representation learning focuses on developing a\n",
      "more instructive feature set for training a classi-\n",
      "ﬁcation model that helps to boost the FR detec-\n",
      "tion process (Li et al., 2017; Yilmaz and Durahim,\n",
      "2018). Within past research, diverse features se-\n",
      "lection methods have been employed to detect FR.\n",
      "Metadata: {'page': 1, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: ﬁcation model that helps to boost the FR detec-\n",
      "tion process (Li et al., 2017; Yilmaz and Durahim,\n",
      "2018). Within past research, diverse features se-\n",
      "lection methods have been employed to detect FR.\n",
      "These may be divided into two classes: review-\n",
      "centric and reviewer-centric features. Reviewer-\n",
      "centric features are related to the reviewer’s be-\n",
      "haviour (Fontanarava et al., 2017) rather than\n",
      "the review itself. Those features include tex-\n",
      "tual features, rating features, and temporal fea-\n",
      "tures. Review-centric features are derived from\n",
      "the content of a review. Commonly used review-\n",
      "centric features include Bag-of-words, TF-IDF\n",
      "(Term-frequency inverse-document- frequency),\n",
      "POS (part of speech) tags, word n-grams (Ahmed\n",
      "et al., 2018), and word embedding vectors (e.g.\n",
      "Word2vec, Doc2vec) (Krishnamurthy et al., 2018;\n",
      "Yilmaz and Durahim, 2018). A recent study by Jia\n",
      "et al. (2018) explored the application of linguis-\n",
      "tic features to distinguish between fake and non-\n",
      "fake reviews. They used Yelp ﬁlter dataset in their\n",
      "study and applied Term Frequency, Word2vec, and\n",
      "Latent Topic Distribution for data representation.\n",
      "They trained three machine learning models i.e.\n",
      "SVM, Logistic Regression, and Multi-layer Per-\n",
      "ceptron and found that LDA+Logistic Regression\n",
      "and LDA+Multi-layer Perceptron performed bet-\n",
      "ter with 81.3% of accuracy.\n",
      "With representations being only a means to en-\n",
      "able better FR identiﬁcation, it is useful to brieﬂy\n",
      "outline the classiﬁcation techniques that have been\n",
      "Metadata: {'page': 1, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: ter with 81.3% of accuracy.\n",
      "With representations being only a means to en-\n",
      "able better FR identiﬁcation, it is useful to brieﬂy\n",
      "outline the classiﬁcation techniques that have been\n",
      "employed for FR detection. Ott et al., (2011) used\n",
      "word n-gram features in combination with a SVM\n",
      "classiﬁer. Banerjee and Chua (2014) employed a\n",
      "Logistic Regression classiﬁer over POS tags and\n",
      "writing style features (e.g., tense of words) for\n",
      "FR detection. Algur et al., (2010) explored a\n",
      "similarity-oriented method for FR detection over\n",
      "domain-speciﬁc product features.\n",
      "As mentioned earlier, our representations are\n",
      "centred on emotion and sentiment based features.\n",
      "There has been very little prior work on using such\n",
      "features for FR detection. An early work in senti-\n",
      "ment analysis for FR detection was conducted by\n",
      "Peng and Zhong (2014), whereas (K et al., 2019)\n",
      "explore utility of emotions in health fake news de-\n",
      "tection. Peng and Zhong (2014) chose SentiWord-\n",
      "Net and MPQA lexicons and analysed sentiment\n",
      "on review and product features. In our experiment,\n",
      "we used IBM, Aﬁnn, SenticNet, and Biu Liu lexi-\n",
      "cons. To our knowledge, this is the ﬁrst study de-\n",
      "tecting FR by means of combination emotion and\n",
      "sentiment analysis. Taking cue from the previous\n",
      "work of FR detection, we use Random Forest clas-\n",
      "siﬁer, in our experiments.\n",
      "3 Methodology\n",
      "In this section we describe our proposed approach\n",
      "to online FR detection using emotion and senti-\n",
      "ment based text representation.\n",
      "3.1 Emotion and Sentiment Analysis\n",
      "Metadata: {'page': 1, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 3 Methodology\n",
      "In this section we describe our proposed approach\n",
      "to online FR detection using emotion and senti-\n",
      "ment based text representation.\n",
      "3.1 Emotion and Sentiment Analysis\n",
      "For the purpose of sentiment and emotion anal-\n",
      "ysis, we apply three different sentiment lexicons\n",
      "and one emotion analysis API.\n",
      "•IBM Watson Natural Language Understand-\n",
      "ing. Natural Language Understanding (NLU) 2\n",
      "is a collection of APIs that offer text analy-\n",
      "sis through natural language processing. One\n",
      "of the feature of IBM Watson NLU is emo-\n",
      "tion analysis. The API takes a text as\n",
      "an input and returns the category which the\n",
      "2https://www.ibm.com/services/natural-language-\n",
      "understanding/\n",
      "Metadata: {'page': 1, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 752\n",
      "text belongs to, stored in a list variable: <\n",
      "KeyV aluePair < String, Double >>e.g.\n",
      "”emotion” : {”sadness”:0.336228}. Each item\n",
      "in the list contains the category (emotion) name\n",
      "and the categorization score. IBM Watson NLU\n",
      "can detect ﬁve emotions: anger, disgust, fear,\n",
      "joy, and sadness. For example, for an an input ’I\n",
      "love apples! I don’t like oranges’, the NLU API\n",
      "returns (sadness: 0.32665, joy: 0.563273, fear:\n",
      "0.033387, disgust: 0.022637, anger: 0.041796).\n",
      "•SenticNet lexicon. SenticNet3 performs tasks\n",
      "such as polarity detection and emotion recog-\n",
      "nition. Instead of merely relying on word co-\n",
      "occurrence frequencies, it leverages semantics\n",
      "and linguistics. This lexicon contains a list of\n",
      "words with their polarity and intensity values.\n",
      "The intensity is a ﬂoat number between -1 and\n",
      "+1. For example, according to the SenticNet\n",
      "lexicon ’abandoned’ is a negative word with in-\n",
      "tensity of -0.85. Each word in the lexicon is\n",
      "assigned with only one polarity and intensity\n",
      "value.\n",
      "•AFINN lexicon. AFINN4 lexicon is a list of\n",
      "English terms rated with valence on a scale -5\n",
      "(negative) and +5 (positive). This lexicon has\n",
      "been manually labelled by Finn ˚Arup Nielsen\n",
      "(2011). AFINN provides two versions of lexi-\n",
      "con: the newest version AFINN-111 with 2477\n",
      "words and phrases and AFINN-96 with 1468\n",
      "unique words and phrases on 1480 lines. Our\n",
      "experiment use AFINN-111 as it is the most up-\n",
      "to-date version.\n",
      "•Biu Liu lexicon. Biu Liu5 lexicon consists of\n",
      "6789 words including 2006 positive and 4783\n",
      "Metadata: {'page': 2, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: unique words and phrases on 1480 lines. Our\n",
      "experiment use AFINN-111 as it is the most up-\n",
      "to-date version.\n",
      "•Biu Liu lexicon. Biu Liu5 lexicon consists of\n",
      "6789 words including 2006 positive and 4783\n",
      "negative words (Hu and Liu, 2004). This lexi-\n",
      "con does not provide any sentiment scores and\n",
      "only provides positive/negative labels.\n",
      "3.2 Representation Learning\n",
      "In this work we explore whether sentiment and\n",
      "emotions extracted from a review can be used to\n",
      "train machine learning models for distinguishing\n",
      "between fake and non-fake reviews. We perform\n",
      "the sentiment/emotion analysis with different lev-\n",
      "els of granularity on a part-by-part basis by seg-\n",
      "menting the reviews.\n",
      "3https://sentic.net/\n",
      "4https://pypi.org/project/aﬁnn/\n",
      "5http://www.cs.uic.edu/˜liub/FBS/opinion-lexicon-\n",
      "English.rar\n",
      "3.2.1 Sentiment Based Representation\n",
      "The process of constructing sentiment based rep-\n",
      "resentation of a review is presented in Algorithm\n",
      "1. We ﬁrst split a review into P segments,\n",
      "each one containing the same number of sen-\n",
      "tences. For example, if P=4, then we split a\n",
      "review into 4 segments. For each segment we\n",
      "identify all positive and all negative words us-\n",
      "ing the lexicons. In the next step, all positive\n",
      "sentiment values and all negative sentiment val-\n",
      "ues within the segment are accumulated together.\n",
      "In the case of AFINN and SenticNet, all posi-\n",
      "tive and negative values are summed in each seg-\n",
      "ment. For Biu Liu lexicon, all positive and all\n",
      "negative words are counted. Following this, the\n",
      "Metadata: {'page': 2, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: In the case of AFINN and SenticNet, all posi-\n",
      "tive and negative values are summed in each seg-\n",
      "ment. For Biu Liu lexicon, all positive and all\n",
      "negative words are counted. Following this, the\n",
      "segment is represented by a two dimensional vec-\n",
      "tor [pos(si), neg(si)], where pos(si) and neg(si)\n",
      "represent the accumulated/counted positive and\n",
      "negative sentiment values. Finally, all P vec-\n",
      "tors (one generated for each segment) are concate-\n",
      "nated. The concatenated vector is returned as the\n",
      "sentiment representation of the entire review. The\n",
      "process looks the same for all sentiment lexicons.\n",
      "Algorithm 1Sentiment Based Representation\n",
      "Input: Review R, number of segments P, senti-\n",
      "ment lexicon L\n",
      "Output: Sentiment representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Tokenise si into set of words W\n",
      "4: Retrieve sentiment values for all words in\n",
      "W using L\n",
      "5: Accumulate all positive sentiment values in\n",
      "W as pos(si)\n",
      "6: Accumulate all negative sentiment values in\n",
      "W as neg(si)\n",
      "7: vi = [pos(si), neg(si)]\n",
      "8: end for\n",
      "9: v(R) := [v1, . . . , vP ]\n",
      "10: return v(R)\n",
      "3.2.2 Emotion Based Representation\n",
      "The process of generating emotion based repre-\n",
      "sentation is presented in Algorithm 2. As in the\n",
      "case of the sentiment based representation, a re-\n",
      "view is ﬁrst divided in P segments. All sentences\n",
      "in each segment is then passed to the IBM Watson\n",
      "API. As the output we obtain vector with the ﬁve\n",
      "emotions’ scores. Finally, the emotion vectors ob-\n",
      "Metadata: {'page': 2, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: view is ﬁrst divided in P segments. All sentences\n",
      "in each segment is then passed to the IBM Watson\n",
      "API. As the output we obtain vector with the ﬁve\n",
      "emotions’ scores. Finally, the emotion vectors ob-\n",
      "tained for all the segments are concatenated. The\n",
      "Metadata: {'page': 2, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 753\n",
      "output vector is returned as the emotion represen-\n",
      "tation of the entire review.\n",
      "Algorithm 2Emotion based Representation\n",
      "Input: Review R, number of segments P, emo-\n",
      "tion lexicon L\n",
      "Output: Emotion representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Get vector vi with emotions scores from L\n",
      "4: end for\n",
      "5: v(R) := [v1, . . . , vP ]\n",
      "6: return v(R)\n",
      "3.2.3 Multi-Segment Based Representation\n",
      "The process of multi-segment representation\n",
      "learning is presented in Algorithm 3. With this\n",
      "technique, the sentiment/emotion based represen-\n",
      "tation is ﬁrst generated for different numbers of\n",
      "segments 1 . . . P. Following this, all vectors ob-\n",
      "tained for p = 1. . . Pare concatenated to form the\n",
      "ﬁnal representation. In this way, the output vector\n",
      "contains more granular information on the distri-\n",
      "bution of sentiment or emotions within a review.\n",
      "Algorithm 3Multi-Segment Representation\n",
      "Input: Review R, maximum number of segments\n",
      "P, lexicon L\n",
      "Output: Vector representation of R\n",
      "1: for allp ∈1 . . . Pdo\n",
      "2: Obtain vp(R) calling Algorithm 1 or 2 and\n",
      "passing R, p and L as parameters\n",
      "3: end for\n",
      "4: v(R) := [v1(R), . . . , vP (R)]\n",
      "5: return v(R)\n",
      "3.2.4 Combined Sentiment and Emotion\n",
      "Based Representation\n",
      "The last representation type that we explore is the\n",
      "combined sentiment and emotion based represen-\n",
      "tation. The process is presented in Algorithm 4.\n",
      "First, a review is divided into P segments. The\n",
      "representation of each segment is generated by\n",
      "Metadata: {'page': 3, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: combined sentiment and emotion based represen-\n",
      "tation. The process is presented in Algorithm 4.\n",
      "First, a review is divided into P segments. The\n",
      "representation of each segment is generated by\n",
      "concatenation of sentiment and emotion represen-\n",
      "tations obtained with Algorithms 1 and 2 respec-\n",
      "tively. Finally, representations of all segments are\n",
      "merged together.\n",
      "Algorithm 4 Combined sentiment and Emotion\n",
      "Based Representation\n",
      "Input: Review R, number of segments P, senti-\n",
      "ment lexicon Ls, emotion lexicon Le\n",
      "Output: Vector representation of R\n",
      "1: Split R into P equal segments s1, . . . , sP\n",
      "2: for alls1, . . . , sP do\n",
      "3: Get sentiment representation Vs(R) apply-\n",
      "ing Algorithm 1 with R, P and Ls\n",
      "4: Get emotion representation Ve(R) applying\n",
      "Algorithm 2 with R, P and Le\n",
      "5: vi = [Vs(R), Ve(R)]\n",
      "6: end for\n",
      "7: v(R) := [v1, . . . , vP ]\n",
      "8: return v(R)\n",
      "4 Experimental Results and Discussion\n",
      "In this section we present the experimental\n",
      "evaluation of the proposed four different senti-\n",
      "ment/emotion based representations. Each of the\n",
      "representations are separetely used to build a ma-\n",
      "chine learning model for FR detection. We con-\n",
      "ducted an extensive set of experiments in order to\n",
      "answer the following key questions:\n",
      "•Do sentiment/emotion based representations\n",
      "help in FR detection?\n",
      "•Which of the proposed representations is the\n",
      "most effective for FR detection?\n",
      "•Can higher sentiment/emotion granularity level\n",
      "improve the data representation?\n",
      "4.1 Experimental Setup\n",
      "Metadata: {'page': 3, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: •Which of the proposed representations is the\n",
      "most effective for FR detection?\n",
      "•Can higher sentiment/emotion granularity level\n",
      "improve the data representation?\n",
      "4.1 Experimental Setup\n",
      "Datasets. We collected our datasets from two\n",
      "different sources. We used gold standard spam\n",
      "review dataset from Ott et al., (2011), and Yelp\n",
      "dataset from Rayana and Akoglu (2015). The Ott\n",
      "dataset contains reviews about hotels. Yelp Zip\n",
      "and Yelp NYC are extracted from Yelp ﬁltered\n",
      "dataset. Yelp NYC is a collection of reviews from\n",
      "restaurants located in New York City (NYC) while\n",
      "Yelp Zip is a collection of restaurant’s reviews in\n",
      "zip code area in NY State. Each of the datasets\n",
      "contains true labels of the reviews, i.e. fake or\n",
      "non-fake label assigned to each review. Table 1\n",
      "shows the size and class distribution for each of\n",
      "the datasets. In our experiment, we only con-\n",
      "sider reviews that contain more than 10 sentences.\n",
      "We presume that proposed representation learning\n",
      "techniques would not be effective for short reviews\n",
      "Metadata: {'page': 3, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 754\n",
      "since sparse text does not allow to identify emo-\n",
      "tions and sentiments well. Table 2 demonstrates\n",
      "the statistics of the datasets after ﬁltering.\n",
      "Dataset Non-fake Fake\n",
      "YELP ZIP 528019 80439\n",
      "YELP NYC 322097 36860\n",
      "Ott 800 800\n",
      "Table 1: Statistics of the datasets\n",
      "Dataset Non-fake Fake\n",
      "YELP ZIP 170261 15108\n",
      "YELP NYC 105080 6185\n",
      "Ott 340 270\n",
      "Table 2: Statistics of the datasets after ﬁltering\n",
      "Learning. As the machine learning algorithm we\n",
      "used Random Forest (RF) given that it was re-\n",
      "ported as one of the most effective in FR detection\n",
      "(Chowdhary and Pandit, 2018; Saumya and Singh,\n",
      "2018; Viviani and Pasi, 2017). However, any other\n",
      "learning algorithm can be applied instead. We set\n",
      "n estimator=100 and random state=42 for the RF\n",
      "parameter. All the experiments are performed with\n",
      "5-fold cross-validation and the prediction perfor-\n",
      "mance is evaluated with application of F-measure.\n",
      "Given the very high class imbalance in the Yelp\n",
      "NYC and Yelp Zip, we randomly select number\n",
      "of non-fake reviews equal to the number of FR in\n",
      "order to balance the training data.\n",
      "4.2 Sentiment and Emotion Granularity\n",
      "In this section we investigate what level of gran-\n",
      "ularity in terms of sentiment and emotion is the\n",
      "most representative for FR detection. Tables 3-5\n",
      "demonstrate the F-measure obtained by RF with\n",
      "each of the datasets and sentiment and emotion\n",
      "based representations for reviews. For the param-\n",
      "eter P we used values from 1 to 4. For each ta-\n",
      "ble, the ﬁrst row represents results obtained by RF\n",
      "Metadata: {'page': 4, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: each of the datasets and sentiment and emotion\n",
      "based representations for reviews. For the param-\n",
      "eter P we used values from 1 to 4. For each ta-\n",
      "ble, the ﬁrst row represents results obtained by RF\n",
      "applied with the emotion based representation ob-\n",
      "tained with the IBM Watson API. The three bot-\n",
      "tom columns contain results obtained for the sen-\n",
      "timent based representation generated with each of\n",
      "the three sentiment lexicons. Each column refers\n",
      "to a different value of parameter P = 1×4. The\n",
      "last column presents results obtained for multi-\n",
      "segment based representation.\n",
      "We can observe from the tables that in the ma-\n",
      "jority of cases, the higher the granularity ( P) the\n",
      "better the prediction performance. It can also be\n",
      "noted that the multi-segment based representation\n",
      "tends to perform better than when a single segmen-\n",
      "tation is applied. The only exception is the Biu Liu\n",
      "lexicon, which for Yelp, Zip, and Ott obtained the\n",
      "best results for P = 1.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.570 0.584 0.589 0.584 0.597\n",
      "SenticNet 0.506 0.510 0.522 0.523 0.524\n",
      "Biu Liu 0.574 0.540 0.547 0.558 0.557\n",
      "AFINN 0.550 0.542 0.549 0.555 0.563\n",
      "Table 3: RF’s F-measure over Yelp ZIP dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.554 0.569 0.578 0.569 0.584\n",
      "SenticNet 0.511 0.520 0.523 0.525 0.526\n",
      "Biu Liu 0.546 0.523 0.543 0.543 0.555\n",
      "AFINN 0.524 0.529 0.541 0.544 0.557\n",
      "Table 4: RF’s F-measure over Yelp NYC dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.620 0.605 0.543 0.533 0.590\n",
      "SenticNet 0.533 0.529 0.483 0.525 0.570\n",
      "Metadata: {'page': 4, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: AFINN 0.524 0.529 0.541 0.544 0.557\n",
      "Table 4: RF’s F-measure over Yelp NYC dataset.\n",
      "Lexicon P=1 P=2 P=3 P=4 P1-4\n",
      "IBM 0.620 0.605 0.543 0.533 0.590\n",
      "SenticNet 0.533 0.529 0.483 0.525 0.570\n",
      "Biu Liu 0.618 0.561 0.592 0.576 0.600\n",
      "AFINN 0.523 0.560 0.580 0.545 0.600\n",
      "Table 5: RF’s F-measure over Ott dataset.\n",
      "4.3 Sentiment vs. Emotion\n",
      "In this section we compare the results obtained by\n",
      "RF applied with the sentiment and the emotion\n",
      "based representations of data. We can see from\n",
      "Tables 3-5 that IBM emotion lexicon obtained the\n",
      "best performance in comparison to the three senti-\n",
      "ment lexicons in the Yelp Zip and NYC datasets.\n",
      "This may be considered unsurprising since emo-\n",
      "tions provide more ﬁne grained information for the\n",
      "classiﬁers to work with. For the Ott dataset, Biu\n",
      "Liu and AFINN lexicon obtained better results for\n",
      "some of the greater values of P.\n",
      "In order to perform better comparison be-\n",
      "tween the sentiment and emotion based rep-\n",
      "resentations we calculated average of the re-\n",
      "sults obtained for each of the granularity levels:\n",
      "P1, P2, P3, P4, P1 −4. The results are demon-\n",
      "strated in Figure 1. We can observe from the\n",
      "graphs that the IBM emotion lexicon performs sig-\n",
      "niﬁcantly better than any of the other sentiment\n",
      "lexicons apart from the Ott dataset where it is out-\n",
      "performed by the Biu Liu lexicon.\n",
      "Metadata: {'page': 4, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 755\n",
      "Figure 1: Average F-measure obtained for all val-\n",
      "ues of P\n",
      "4.4 Combined Sentiment and Emotion Based\n",
      "Representation\n",
      "Table 6 demonstrates results obtained for the com-\n",
      "bined sentiment and emotion based representation\n",
      "generated according to the Algorithm 4. We can\n",
      "observe that for Zip and NYC datasets the best\n",
      "results were obtained when multi-segment based\n",
      "representation was applied. With Ott the best per-\n",
      "formance was obtained for P1.\n",
      "Dataset P1 P2 P3 P4 P1-4\n",
      "ZIP 0.589 0.596 0.599 0.599 0.602\n",
      "NYC 0.580 0.580 0.589 0.584 0.588\n",
      "Ott 0.653 0.624 0.606 0.604 0.640\n",
      "Table 6: F-measure obtained with combined sen-\n",
      "timent and emotion representation learning.\n",
      "In Figures 2-4 we compare the performance of\n",
      "the combined sentiment and emotion based repre-\n",
      "sentation with the emotion based representation,\n",
      "which so far obtained the most promising results.\n",
      "We can observe that the combined approach ob-\n",
      "tained better results in each case, with the dif-\n",
      "ference in F-measure being quite signiﬁcant for\n",
      "Zip and NYC datasets. This demonstrate that im-\n",
      "proved data representation can be achieved by ap-\n",
      "plying combination of different emotion and sen-\n",
      "timent extraction methods.\n",
      "5 Conclusions and Future Work\n",
      "In this paper, we analyzed the effectiveness of\n",
      "emotion and sentiment based representations esti-\n",
      "mated over varying text grabularities, for the task\n",
      "of fake review classiﬁcation. Through an em-\n",
      "pirical study across three real-world datasets, we\n",
      "ﬁnd consistent evidence that combinations of emo-\n",
      "Metadata: {'page': 5, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: mated over varying text grabularities, for the task\n",
      "of fake review classiﬁcation. Through an em-\n",
      "pirical study across three real-world datasets, we\n",
      "ﬁnd consistent evidence that combinations of emo-\n",
      "tions and sentiments work better than either of\n",
      "Figure 2: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for Zip\n",
      "Figure 3: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for NYC\n",
      "Figure 4: Combined sentiment-emotion vs. emo-\n",
      "tion representation learning for Ott\n",
      "them separately. Further, we observe that com-\n",
      "bining emotion and sentiment representations ob-\n",
      "tained across different text granularities yields bet-\n",
      "ter accuracies over the restaurant review datasets.\n",
      "As future work, we plan to carry on research\n",
      "on cross domain between different datasets. We\n",
      "also want to observe how sentiment and emotion\n",
      "work on neural network model such as CNN and\n",
      "LSTM using generic as well as custom-built lexi-\n",
      "cons (Bandhakavi et al., 2017).\n",
      "Metadata: {'page': 5, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 756\n",
      "   \n",
      "Acknowledgments \n",
      "The authors thank LPDP (Indonesia Endowment \n",
      "Fund for Education) for funding this research.  \n",
      " \n",
      "References  \n",
      "Ahmed, Hadeer, et al. “Detecting Opinion Spams and \n",
      "Fake News Using Text Classification.” Security \n",
      "and Privacy , vol. 1, no. 1, 2017, p. e9, \n",
      "doi:10.1002/spy2.9. \n",
      "Algur, Siddu P., et al. “Conceptual Level Similarity \n",
      "Measure Based Review Spam Detection.” \n",
      "Proceedings of the 2010 International \n",
      "Conference on Signal and Image Processing, \n",
      "ICSIP 2010 , IEEE, 2010, pp. 416 –23, \n",
      "doi:10.1109/ICSIP.2010.5697509. \n",
      "Anoop, K., et al. “Emotion Cognizance Improves Fake \n",
      "News Identification.” ArXiv Preprint \n",
      "ArXiv:1906.10365, 2019. \n",
      "Bandhakavi, Anil, et al. “Lexicon Generation for \n",
      "Emotion Detection from Text.” IEEE Intelligent \n",
      "Systems, vol. 32, no. 1, IEEE, 2017, pp. 102 –08, \n",
      "doi:10.1109/MIS.2017.22. \n",
      "Banerjee, Snehasish, and Alton Y. K. Chua. \n",
      "“Applauses in Hotel Reviews: Genuine or \n",
      "Deceptive?” Proceedings of 2014 Science and \n",
      "Information Conference, SAI 2014 , The Science \n",
      "and Information (SAI) Organization, 2014, pp. \n",
      "938–42, doi:10.1109/SAI.2014.6918299. \n",
      "Bengio, Yoshua, et al. “Representation Learning: A \n",
      "Review and New Perspectives. ” IEEE \n",
      "Transactions on Pattern Analysis and Machine \n",
      "Intelligence, vol. 35, no. 8, IEEE, 2013, pp. \n",
      "1798–828. \n",
      "Chowdhary, Neha S., and Anala A. Pandit. “Fake \n",
      "Review Detection Using Classification.” \n",
      "International Journal of Computer Applications, \n",
      "vol. 180, no. 50, 2018, pp. 16–21.\n",
      "Metadata: {'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 1798–828. \n",
      "Chowdhary, Neha S., and Anala A. Pandit. “Fake \n",
      "Review Detection Using Classification.” \n",
      "International Journal of Computer Applications, \n",
      "vol. 180, no. 50, 2018, pp. 16–21. \n",
      "Fontanarava, Julien, et al. “Feature Analysis for Fake \n",
      "Review Detection through Supervised \n",
      "Classification.” 2017 IEEE International \n",
      "Conference on Data Science and Advanced \n",
      "Analytics (DSAA), IEEE, 2017, pp. 658–66. \n",
      "Hu, Minqing, and Bing Liu. “Mining and Summarizing \n",
      "Customer Reviews.” Proceedings of the Tenth \n",
      "ACM SIGKDD International Conference on \n",
      "Knowledge Discovery and Data Mining, vol. 50, \n",
      "no. 08, 2004, pp. 50 -4466-50–4466, \n",
      "doi:10.5860/choice.50-4466. \n",
      "Jia, Shaohua, et al. “Fake Reviews Detection Based on \n",
      "LDA.” 2018 4th International Conference on \n",
      "Information Management, ICIM 2018 , IEEE, \n",
      "2018, pp. 280 –83, \n",
      "doi:10.1109/INFOMAN.2018.8392850. \n",
      "Jindal, Nitin, and Bing Liu. “Opinion Spam and \n",
      "Analysis.” Proceedings of the 2008 International \n",
      "Conference on Web Search and Data Mining , \n",
      "ACM, 2008, pp. 219–30. \n",
      "Krishnamurthy, Gangeshwar, et al. “A Deep Learning \n",
      "Approach for Multimodal Deception Detection.” \n",
      "ArXiv Preprint ArXiv:1803.00344, 2018. \n",
      "Kumar, Abhinav, et al. “Spotting Opinion Spammers \n",
      "Using Be havioral Footprints.” Proceedings of \n",
      "the 19th ACM SIGKDD International \n",
      "Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam\n",
      "Metadata: {'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam \n",
      "Review Detection.” Neurocomputing, vol. 254, \n",
      "Elsevier B.V., 2017, pp. 1339 –51, \n",
      "doi:10.1016/j.neucom.2016.10.080. \n",
      "Luca, Michael, and Georgios Zervas. “Fake It till You \n",
      "Make It: Reputation.” Competition, and Yelp \n",
      "Review Fraud., SSRN Electronic Journal, 2016. \n",
      "Nielsen, Finn Årup. “A New ANEW: Evaluation of a \n",
      "Word List for Sentiment Analysis in \n",
      "Microblogs.” CEUR Workshop Proceedings , \n",
      "vol. 718, 2011, pp. 93 –98, \n",
      "doi:10.1016/j.knosys.2015.06.015. \n",
      "Ott, Myle, et al. “Finding Deceptive Opinion Spam by \n",
      "Any Stretch of the Imagination.” Proceedings of \n",
      "the 49th Annual Meeting of the Association for \n",
      "Computational Linguistics: Human Language \n",
      "Technologies-Volume 1 , Association for \n",
      "Computational Linguistics, 2011, pp. 309–19. \n",
      "Peng, Qingxi, and Ming Zhong. “Detecting Spam \n",
      "Review through Sentiment AnalysisPeng, Q. and \n",
      "Zhong, M. (2014) ‘Detecting Spam Review \n",
      "through Sentiment Analysis’, Journal of \n",
      "Software. Doi: 10.4304/Jsw.9.8.2065 -2072.” \n",
      "Journal of Software , 2014, \n",
      "doi:10.4304/jsw.9.8.2065-2072. \n",
      "Rayana, Shebuti. “Collective Opinion Spam  \n",
      "Detection : Bridging Review Networks and \n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no.\n",
      "Metadata: {'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no. \n",
      "3, Multimedia Tools and Applications, 2017, pp. \n",
      "3187–211, doi:10.1007/s11042-016-3819-y.\n",
      "Metadata: {'page': 6, 'source': '../RAG-PDF/content/emotion.pdf'}\n",
      "Document: 757\n",
      "   \n",
      "Saumya, Sunil, and Jyoti Prakash Singh. “Detection of \n",
      "Spam Reviews: A Sentiment Analysis \n",
      "Approach.” CSI Transactions on ICT, vol. 6, no. \n",
      "2, Springer, 2018, pp. 137–48. \n",
      "Viviani, Marco, and Gabriella Pasi. “Quantifier Guided \n",
      "Aggregation for the Veracity Assessment of \n",
      "Online Reviews.” International Journal of \n",
      "Intelligent Systems, vol. 32, no. 5, Wiley Online \n",
      "Library, 2017, pp. 481–501. \n",
      "Yilmaz, Cennet Merve, and Ahmet Onur Durahim. \n",
      "“SPR2EP: A S emi-Supervised Spam Review \n",
      "Detection Framework.” Proceedings of the 2018 \n",
      "IEEE/ACM International Conference on \n",
      "Advances in Social Networks Analysis and \n",
      "Mining, ASONAM 2018 , 2018, pp. 306 –13, \n",
      "doi:10.1109/ASONAM.2018.8508314.\n",
      "Metadata: {'page': 7, 'source': '../RAG-PDF/content/emotion.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Access stored documents and metadata\n",
    "docs = vectorstore._collection.get()\n",
    "for doc, metadata in zip(docs['documents'], docs['metadatas']):\n",
    "    print(f\"Document: {doc}\")\n",
    "    print(f\"Metadata: {metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the nunmber of stored chunks\n",
    "docs = vectorstore._collection.get()\n",
    "print(f\"Number of stored chunks: {len(docs['documents'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Retriever for Targeted Debugging\n",
    "retrieved_docs = vectorstore.as_retriever().get_relevant_documents(\"What is the title of the paper?\")\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_query = \"What is the title of this paper?\"\n",
    "summary_query = \"What is the summary of this paper?\"\n",
    "year_query = \"What is the publication year of this paper?\"\n",
    "authors_query = \"Who are the authors of this paper?\"\n",
    "\n",
    "\n",
    "title = rag_chain.invoke(title_query)\n",
    "summary = rag_chain.invoke(summary_query)\n",
    "year = rag_chain.invoke(year_query)\n",
    "authors = rag_chain.invoke(authors_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template \n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "# PROMPT_TEMPLATE = \"\"\"\n",
    "# You are an assistant for extracting information about research articles.\n",
    "# Use the retrieved context to extract the following information:\n",
    "\n",
    "# - Title of the article\n",
    "# - Summary of the article\n",
    "# - Year of publication\n",
    "# - Names of the authors\n",
    "\n",
    "# If any field is not explicitly mentioned in the context, say \"Not available.\"\n",
    "\n",
    "# Context:\n",
    "# {context}\n",
    "\n",
    "# Question:\n",
    "# {question}\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an assistant for question-answering tasks.\n",
      "Use the following pieces of retrieved context to answer\n",
      "the question. If you don't know the answer, say that you\n",
      "don't know. DON'T MAKE UP ANYTHING.\n",
      "\n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no. \n",
      "3, Multimedia Tools and Applications, 2017, pp. \n",
      "3187–211, doi:10.1007/s11042-016-3819-y.\n",
      "\n",
      "---\n",
      "\n",
      "Conference on Knowledge Discovery and Data \n",
      "Mining, ACM, 2013, \n",
      "doi:10.1145/2487575.2487580. \n",
      "Li, Luyang, et al. “Document Representation and \n",
      "Feature Combination for Deceptive Spam \n",
      "Review Detection.” Neurocomputing, vol. 254, \n",
      "Elsevier B.V., 2017, pp. 1339 –51, \n",
      "doi:10.1016/j.neucom.2016.10.080. \n",
      "Luca, Michael, and Georgios Zervas. “Fake It till You \n",
      "Make It: Reputation.” Competition, and Yelp \n",
      "Review Fraud., SSRN Electronic Journal, 2016. \n",
      "Nielsen, Finn Årup. “A New ANEW: Evaluation of a \n",
      "Word List for Sentiment Analysis in \n",
      "Microblogs.” CEUR Workshop Proceedings , \n",
      "vol. 718, 2011, pp. 93 –98, \n",
      "doi:10.1016/j.knosys.2015.06.015. \n",
      "Ott, Myle, et al. “Finding Deceptive Opinion Spam by \n",
      "Any Stretch of the Imagination.” Proceedings of \n",
      "the 49th Annual Meeting of the Association for \n",
      "Computational Linguistics: Human Language \n",
      "Technologies-Volume 1 , Association for \n",
      "Computational Linguistics, 2011, pp. 309–19. \n",
      "Peng, Qingxi, and Ming Zhong. “Detecting Spam \n",
      "Review through Sentiment AnalysisPeng, Q. and \n",
      "Zhong, M. (2014) ‘Detecting Spam Review \n",
      "through Sentiment Analysis’, Journal of \n",
      "Software. Doi: 10.4304/Jsw.9.8.2065 -2072.” \n",
      "Journal of Software , 2014, \n",
      "doi:10.4304/jsw.9.8.2065-2072. \n",
      "Rayana, Shebuti. “Collective Opinion Spam  \n",
      "Detection : Bridging Review Networks and \n",
      "Metadata.” Proceedings of the 21th ACM \n",
      "SIGKDD, 2015. \n",
      "Rout, Jitendra Kumar, et al. “Deceptive Review \n",
      "Detection Using Labeled and Unlabeled Data.” \n",
      "Multimedia Tools and Applications , vol. 76, no.\n",
      "\n",
      "---\n",
      "\n",
      "757\n",
      "   \n",
      "Saumya, Sunil, and Jyoti Prakash Singh. “Detection of \n",
      "Spam Reviews: A Sentiment Analysis \n",
      "Approach.” CSI Transactions on ICT, vol. 6, no. \n",
      "2, Springer, 2018, pp. 137–48. \n",
      "Viviani, Marco, and Gabriella Pasi. “Quantifier Guided \n",
      "Aggregation for the Veracity Assessment of \n",
      "Online Reviews.” International Journal of \n",
      "Intelligent Systems, vol. 32, no. 5, Wiley Online \n",
      "Library, 2017, pp. 481–501. \n",
      "Yilmaz, Cennet Merve, and Ahmet Onur Durahim. \n",
      "“SPR2EP: A S emi-Supervised Spam Review \n",
      "Detection Framework.” Proceedings of the 2018 \n",
      "IEEE/ACM International Conference on \n",
      "Advances in Social Networks Analysis and \n",
      "Mining, ASONAM 2018 , 2018, pp. 306 –13, \n",
      "doi:10.1109/ASONAM.2018.8508314.\n",
      "\n",
      "---\n",
      "\n",
      "Proceedings of Recent Advances in Natural Language Processing, pages 750–757,\n",
      "Varna, Bulgaria, Sep 2–4, 2019.\n",
      "https://doi.org/10.26615/978-954-452-056-4_087\n",
      "750\n",
      "Sentiment and Emotion Based Text\n",
      "Representation for Fake Reviews Detection\n",
      "Alimuddin Melleng\n",
      "Queen’s University Belfast\n",
      "amelleng01@qub.ac.uk\n",
      "Anna-Jurek Loughrey\n",
      "Queen’s University Belfast\n",
      "a.jurek@qub.ac.uk\n",
      "Deepak P\n",
      "Queen’s University Belfast\n",
      "deepaksp@acm.org\n",
      "Abstract\n",
      "Fake reviews are increasingly prevalent\n",
      "across the Internet. They can be uneth-\n",
      "ical and harmful. They can affect busi-\n",
      "nesses and mislead customers. As opin-\n",
      "ions on the Web are increasingly relied on,\n",
      "the detection of fake reviews has become\n",
      "more critical. In this study we explore\n",
      "the effectiveness of sentiment and emo-\n",
      "tions based representations for the task\n",
      "of building machine learning models for\n",
      "fake reviews detection. The experiment\n",
      "performed with three real-world datasets\n",
      "demonstrate that improved data represen-\n",
      "tation can be achieved by combining sen-\n",
      "timent and emotion extraction methods, as\n",
      "well as by performing sentiment and emo-\n",
      "tion analysis on a part-by-part basis by\n",
      "segmenting the reviews.\n",
      "1 Introduction\n",
      "The Internet has evolved into a content creation\n",
      "platform where people express their opinions and\n",
      "experiences. Online reviews written by users have\n",
      "signiﬁcant impact on customers and companies.\n",
      "Potential customers often consult reviews before\n",
      "making a purchase. Reviews help potential cus-\n",
      "tomers to gain insights from other people’s ex-\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: What is the title of the paper?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate context text\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# Create prompt\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text,\n",
    "                                question=\"What is the title of the paper?\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The title of the paper is \"Sentiment and Emotion Based Text Representation for Fake Reviews Detection.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 1206, 'total_tokens': 1226, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-62b43325-5d19-4b26-a59f-dfd96e5e7075-0', usage_metadata={'input_tokens': 1206, 'output_tokens': 20, 'total_tokens': 1226, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The title of the paper is \"Sentiment and Emotion Based Text Representation for Fake Reviews Detection.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 1200, 'total_tokens': 1220, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-d4bfbddb-bc43-4450-beca-0c4448de8fe6-0', usage_metadata={'input_tokens': 1200, 'output_tokens': 20, 'total_tokens': 1220, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "    | prompt_template\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# rag_chain.invoke(\"What is the title of the article?\")\n",
    "rag_chain.invoke(\"what's the title of this paper.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Structured responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted Information about the research paper\"\"\"\n",
    "    paper_title: str = Field(description=\"Title of the paper\")\n",
    "    paper_summary: str = Field(description=\"Summary of the paper\")\n",
    "    publication_year: int = Field(description=\"Year of publication of the paper\")\n",
    "    paper_authors: str = Field(description=\"Names of the authors of the paper\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractedInfo(paper_title=AnswerWithSources(answer='Sentiment and Emotion Based Text Representation for Fake Reviews Detection', sources='Sentiment and Emotion Based Text Representation for Fake Reviews Detection Alimuddin Melleng Queen’s University Belfast amelleng01@qub.ac.uk Anna-Jurek Loughrey Queen’s University Belfast a.jurek@qub.ac.uk Deepak P Queen’s University Belfast deepaksp@acm.org', reasoning='The title is explicitly mentioned at the beginning of the provided context.'), paper_summary=AnswerWithSources(answer='Fake reviews are increasingly prevalent across the Internet and can be unethical and harmful, affecting businesses and misleading customers. The study explores the effectiveness of sentiment and emotion-based representations for detecting fake reviews.', sources='Fake reviews are increasingly prevalent across the Internet. They can be unethical and harmful. They can affect businesses and mislead customers. As opinions on the Web are increasingly relied on, the detection of fake reviews has become more critical.', reasoning='The summary captures the main theme and focus of the research study, which is about the impact of fake reviews and the methods to detect them.'), publication_year=AnswerWithSources(answer='2019', sources='Proceedings of Recent Advances in Natural Language Processing, pages 750–757, Varna, Bulgaria, Sep 2–4, 2019.', reasoning='The publication year is specified in the context as part of the event details where the paper was presented.'), paper_authors=AnswerWithSources(answer='Alimuddin Melleng, Anna-Jurek Loughrey, Deepak P', sources='Alimuddin Melleng Queen’s University Belfast amelleng01@qub.ac.uk Anna-Jurek Loughrey Queen’s University Belfast a.jurek@qub.ac.uk Deepak P Queen’s University Belfast deepaksp@acm.org', reasoning=\"The authors' names are listed alongside their affiliations in the context.\"))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"what is the title of the research paper.\")\n",
    "# rag_chain.invoke(\"what is the title, summary, publication date, authors of the research paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"what is the title, summary, publication date, authors of the research paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform response into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithSources(BaseModel):\n",
    "    \"\"\"An answer to the question, with sources and reasoning\"\"\"\n",
    "    answer: str=Field(description=\"Answer to question\")\n",
    "    sources: str = Field(description=\"Full direct text chunk from the context used to answer the question\")\n",
    "    reasoning: str = Field(description=\"Explain the reasoning of the answer based on the sources\")\n",
    "    \n",
    "\n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted Information about the research article\"\"\"\n",
    "    paper_title: AnswerWithSources\n",
    "    paper_summary: AnswerWithSources\n",
    "    publication_year: AnswerWithSources\n",
    "    paper_authors: AnswerWithSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_summary</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>paper_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>Sentiment and Emotion Based Text Representatio...</td>\n",
       "      <td>The study explores the effectiveness of sentim...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Alimuddin Melleng, Anna-Jurek Loughrey, Deepak P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sources</th>\n",
       "      <td>Sentiment and Emotion Based Text Representatio...</td>\n",
       "      <td>In this study we explore the effectiveness of ...</td>\n",
       "      <td>Proceedings of Recent Advances in Natural Lang...</td>\n",
       "      <td>Alimuddin Melleng Queen’s University Belfast, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning</th>\n",
       "      <td>The title is explicitly mentioned at the begin...</td>\n",
       "      <td>The summary is derived from the abstract where...</td>\n",
       "      <td>The publication year is indicated in the metad...</td>\n",
       "      <td>The authors' names are listed in the abstract ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 paper_title  \\\n",
       "answer     Sentiment and Emotion Based Text Representatio...   \n",
       "sources    Sentiment and Emotion Based Text Representatio...   \n",
       "reasoning  The title is explicitly mentioned at the begin...   \n",
       "\n",
       "                                               paper_summary  \\\n",
       "answer     The study explores the effectiveness of sentim...   \n",
       "sources    In this study we explore the effectiveness of ...   \n",
       "reasoning  The summary is derived from the abstract where...   \n",
       "\n",
       "                                            publication_year  \\\n",
       "answer                                                  2019   \n",
       "sources    Proceedings of Recent Advances in Natural Lang...   \n",
       "reasoning  The publication year is indicated in the metad...   \n",
       "\n",
       "                                               paper_authors  \n",
       "answer      Alimuddin Melleng, Anna-Jurek Loughrey, Deepak P  \n",
       "sources    Alimuddin Melleng Queen’s University Belfast, ...  \n",
       "reasoning  The authors' names are listed in the abstract ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structured_response = rag_chain.invoke(\"Give me the title, summary, publication data, authors of the research paper\")\n",
    "structured_response = rag_chain.invoke(\"what is the title of the research paper.\")\n",
    "df = pd.DataFrame([structured_response.dict()])\n",
    "\n",
    "# Transorming into a table with two rows: 'answer' and 'source'\n",
    "answer_row = []\n",
    "source_row = []\n",
    "reasoning_row = []\n",
    "\n",
    "for col in df.columns:\n",
    "    answer_row.append(df[col][0]['answer'])\n",
    "    source_row.append(df[col][0]['sources'])\n",
    "    reasoning_row.append(df[col][0]['reasoning'])\n",
    "    \n",
    "# Create new dataframe with two rows: 'answer' and 'souce' \n",
    "structured_response_df = pd.DataFrame([answer_row, source_row, reasoning_row], columns=df.columns, index=['answer','sources','reasoning'])\n",
    "structured_response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/59chk2cj6wn3knsk_207kwfm0000gp/T/ipykernel_96166/305324772.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  structured_response_df['paper_authors'][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Alimuddin Melleng, Anna-Jurek Loughrey, Deepak P'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_response_df['paper_authors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
